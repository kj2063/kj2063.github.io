<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 5.2.0"/><meta name="description" content="Welcome to Jun&#x27;s Blog" data-gatsby-head="true"/><meta property="og:title" content="[논문 리뷰] R-CNN" data-gatsby-head="true"/><meta property="og:description" content="Welcome to Jun&#x27;s Blog" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta name="twitter:card" content="summary" data-gatsby-head="true"/><meta name="twitter:creator" content="@kj2063" data-gatsby-head="true"/><meta name="twitter:title" content="[논문 리뷰] R-CNN" data-gatsby-head="true"/><meta name="twitter:description" content="Welcome to Jun&#x27;s Blog" data-gatsby-head="true"/><style data-href="/styles.f59352273b927e8a375c.css" data-identity="gatsby-global-css">:root{--border-radius:4px;--color-text:#111;--color-dark-text:#fff;--color-primary:#149494;--color-secondary:#969696;--color-code-bg:#fff4db;--color-code:#8a6534;--font-sans:-apple-system,BlinkMacSystemFont,"Segoe UI",Helvetica,Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji";--font-mono:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;--font-lg:18px;--font-md:16px;--font-sm:14px;--font-sx:12px;--line-height-loose:1.75;--line-height-normal:1.5;--line-height-dense:1.1;--space-1:4px;--space-2:8px;--space-3:16px;--space-4:24px;--space-5:32px;--space-6:64px;--size-content:54rem;--size-gutter:var(--space-5);--size-gap:var(--space-6)}html{-webkit-text-size-adjust:100%;box-sizing:border-box;font:sans-serif;font-size:var(--font-md);line-height:var(--line-height-normal);overflow-y:scroll}body{-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;word-wrap:break-word;color:var(--color-text);font-family:sans-serif;font-family:var(--font-sans);font-weight:400;margin:0}.main_a{font-weight:500;text-decoration:none;text-decoration-thickness:1.5px;text-underline-offset:2px}a:active,a:hover{outline-width:0;text-decoration:underline}abbr[title]{border-bottom:1px dotted rgba(0,0,0,.5);cursor:help;text-decoration:none}b,strong{font-weight:inherit;font-weight:bolder}dfn{font-style:italic}h1{letter-spacing:-.01em;line-height:var(--line-height-dense);margin:0 0 3rem;padding:0}.mainColor{color:var(--color-primary)}img{border-style:none;max-width:100%}code,kbd,pre,samp{font-family:var(--font-mono);font-size:1em;line-height:inherit}hr{background:rgba(0,0,0,.2);border:none;box-sizing:content-box;height:1px;margin-bottom:calc(var(--space-4) - 1px);margin-left:0;margin-right:0;margin-top:0;overflow:visible;padding:0}*,:after,:before{box-sizing:inherit}dd,dl,fieldset,figure,hgroup,img,ol,p,ul{margin:0;margin-bottom:var(--space-4);padding:0}ol,ul{list-style-image:none;list-style-position:outside;margin-left:var(--space-4)}pre{word-wrap:normal;background:rgba(0,0,0,.04);border-radius:var(--border-radius);font-size:.875rem;line-height:var(--line-height-normal);margin-bottom:var(--space-4);margin-left:0;margin-right:0;margin-top:0;overflow:auto;padding:var(--space-4)}b,dt,strong,th{font-weight:700}li{margin-bottom:calc(var(--space-4)/2)}ol li,ul li{padding-left:0}li>ol,li>ul{margin-bottom:calc(var(--space-4)/2);margin-left:var(--space-4);margin-top:calc(var(--space-4)/2)}blockquote :last-child,li :last-child,p :last-child{margin-bottom:0}li>p{margin-bottom:calc(var(--space-4)/2)}p{max-width:680px}code,kbd,samp{font-size:.875rem}abbr,acronym{border-bottom:1px dotted rgba(0,0,0,.5);cursor:help}code,tt{background-color:var(--color-code-bg);border-radius:var(--border-radius);color:var(--color-code);font-family:var(--font-mono);padding-bottom:.25em;padding-top:.25em;word-break:normal}pre code{background:none}code:after,code:before,tt:after,tt:before{content:"\00a0";letter-spacing:-.2em}pre code:after,pre code:before,pre tt:after,pre tt:before{content:none}.dark-switcher{background:transparent;border:none;cursor:pointer}.dark{background-color:#2a2b2d;color:var(--color-dark-text)}.dark,.light{transition:all .6s ease}.light{background-color:#fefefe}:where(.css-dev-only-do-not-override-pl1kfr).ant-tag{border-color:#149494;color:#149494}
/*  !* https://css-tricks.com/responsive-layouts-fewer-media-queries/ *!*/.mgl30{margin-left:30px}.textCenter{text-align:center}.floatRight{float:right}.floatLeft{float:left}.introductionText{font-size:large;font-weight:700;margin-top:20px}.careerDiv{margin-top:120px}.careerDiv h2{border-bottom:2px dashed #ccc;color:var(--color-primary);padding-bottom:10px;text-align:center}.careerDiv p{font-weight:700}.careerDiv li{font-weight:400}.careerDiv li::marker{color:var(--color-primary)}.careerContentsDiv{margin-bottom:40px}.careerPeriodDiv{color:var(--color-primary);font-weight:700;margin-bottom:10px;min-width:200px}.careerDetailDiv{flex-basis:580px;margin-left:20px}.flexBox{display:flex;flex-direction:row;flex-wrap:wrap}.titleStyle{font-size:x-large;font-weight:lighter;text-decoration:none}.titleStyle:hover{text-decoration:underline;text-decoration-thickness:1px;text-underline-offset:8px}.light .titleStyle,.light .titleStyle:visited{color:var(--color-text)}.dark .titleStyle,.dark .titleStyle:visited{color:var(--color-dark-text)}.dateStyle{color:var(--color-secondary);font-size:large;font-weight:lighter}.postDiv{margin-bottom:20px;margin-top:20px}.blogTable>tr,td,th{border:none!important;text-align:left!important}.flexWarp{display:flex;justify-content:space-between}.gridAlignCenter{display:grid;place-items:center}blockquote{border-left:1px solid var(--color-secondary);border:1px solid var(--color-secondary);border-left-width:10px;margin-left:0;margin-right:0;padding-left:20px;padding-right:20px}table{border-collapse:collapse;line-height:1.5;text-align:left}table thead th{border-bottom:2px solid var(--color-secondary);border-top:2px solid var(--color-secondary);color:var(--color-secondary);padding:10px;text-align:center}table tbody th,table thead th{font-weight:700;vertical-align:top}table tbody th{background:#f3f6f7}table tbody th,table td{border-bottom:1px solid #ccc;padding:10px 15px}table td{text-align:center;vertical-align:middle}</style><title data-gatsby-head="true">[논문 리뷰] R-CNN | Jun&#x27;s Blog</title><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){const t=e.target;if(void 0===t.dataset.mainImage)return;if(void 0===t.dataset.gatsbyImageSsr)return;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><link rel="icon" href="/favicon-32x32.png?v=b20f0fbf11cd092c3e4d2fbbc31cfa13" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=b20f0fbf11cd092c3e4d2fbbc31cfa13"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=b20f0fbf11cd092c3e4d2fbbc31cfa13"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=b20f0fbf11cd092c3e4d2fbbc31cfa13"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=b20f0fbf11cd092c3e4d2fbbc31cfa13"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=b20f0fbf11cd092c3e4d2fbbc31cfa13"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=b20f0fbf11cd092c3e4d2fbbc31cfa13"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=b20f0fbf11cd092c3e4d2fbbc31cfa13"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=b20f0fbf11cd092c3e4d2fbbc31cfa13"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="light"><div><header style="margin:0 auto;padding:var(--space-4) var(--size-gutter);display:flex;align-items:center;justify-content:space-between"><a class="main_a mainColor" style="font-size:var(--font-md);text-decoration:none;font-weight:lighter;text-decoration-line:underline" href="/"><b>Jun&#x27;s Blog</b></a><div><a class="main_a mainColor" style="font-size:var(--font-sm);text-decoration:none" href="/blog/">Blog</a>  <a class="main_a mainColor" style="font-size:var(--font-sm);text-decoration:none" href="/about/">About</a>  <button class="dark-switcher"><b>☾</b></button></div></header></div><div style="margin:0 auto;max-width:var(--size-content);padding:var(--size-gutter)"><main><div><h2 class="mainColor">Blog</h2><div><h1 class="mgl30" style="font-weight:lighter;margin-top:30px">[논문 리뷰] R-CNN</h1><div><br>
<h1>R-CNN</h1>
<h2>R-CNN 의 개요</h2>
<div style="text-align: center;">
    <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; ">
      <a class="gatsby-resp-image-link" href="/static/ea3f7281e7a7fc01de84c10c5550e97d/21b4d/R-CNN_features.png" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 37%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAABYlAAAWJQFJUiTwAAABpElEQVQoz12QX2vTUBjG+5X8JvsIIuLVvBEV9M6BspshVSZOcTfKnI7hHzZ0mxctOnCVNE0po/lPk3Q2SbtkbZp0Le1PzvFC8IUn5/AGnuf5nRL/jef5tHULy3Zotw1+npyg6zr1uiLPVquFoihS/X6f+XzOdDplNpuxWCwoDYdDvn3eprK/xfHXt/TOfKoHL6h8eUJl7zldPyCMQhkUx7EMFSbCoNPpYFkWruuSJIn8V0rSlKcbr7h36w4fnt3lLNDY2HzA/dvXebd+A63+nZ03a6i/jnBcj2ZTk00Nw8BxHDzPkxLFZMMo7vPo4Qor15Z4v7ZM4KmUy1dZvXmF7fIStqmws7nKaaNKFJ8ThSFBEKBpGrZt4/s+3W6X0Wj013BSFFT3d/n0+iXHBx+Jez5He+sc7j7mx2GZ3m9HogjEKAoldlEUcieQhXGj0ZAhEll8srxAUTVGWU4UxWjNUwzLwTBddN2Ub2aaJqqqUqvVJKKY8XgsDYXyPP9nOL28ZDAYyBYiPUnOGV5ckOdjJpOJRBF7IYEmjMROTJqmZFkm7wL5D46/8hmu/+hyAAAAAElFTkSuQmCC'); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="R CNN features" title="" src="/static/ea3f7281e7a7fc01de84c10c5550e97d/5a190/R-CNN_features.png" srcset="/static/ea3f7281e7a7fc01de84c10c5550e97d/772e8/R-CNN_features.png 200w,
/static/ea3f7281e7a7fc01de84c10c5550e97d/e17e5/R-CNN_features.png 400w,
/static/ea3f7281e7a7fc01de84c10c5550e97d/5a190/R-CNN_features.png 800w,
/static/ea3f7281e7a7fc01de84c10c5550e97d/c1b63/R-CNN_features.png 1200w,
/static/ea3f7281e7a7fc01de84c10c5550e97d/21b4d/R-CNN_features.png 1280w" sizes="(max-width: 800px) 100vw, 800px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
</div>
<ol>
<li>입력 이미지를 받는다.<br></li>
<li><code>Selective Search</code> 를 통해 약 2000 여개의 영역을 제안(Region Proposals)한다.<br> + 제안된 영역을 CNN을 사용하여 features를 얻기 위해 CNN의 input크기에 맞춰 일정한 크기로 조정한다.<br></li>
<li>크기를 조정한 영역을 <code>CNN(AlexNet)</code>에 넣어 features를 얻는다.<br></li>
<li><code>Support Vector machines(SVM)</code>을 이용하여 구해진 features를 분류한다.<br><br></li>
</ol>
<h3>Abstract</h3>
<p> 본 논문은 두가지 핵심을 사용한다.<br></p>
<ol>
<li>객체 탐지를 위한 Region Proposals 에 CNN을 적용한다.<br></li>
<li>labeled 된 훈련 데이터가 부족할때 <code>supervised pre-training</code> 과 <code>domain-specific fine-tuning</code> 을 통해 성능을 향상시킨다.<br><br></li>
</ol>
<h2>Object detection with R-CNN</h2>
<ul>
<li>
<h3>Object Localization</h3>
<p> 논문에서 object localization을 위해 3가지 방법을 제시한다.<br><br></p>
<ol>
  <li>
    <b>Regression</b><br>
    &nbsp;Szegedy 의 연구의 결과로 좋지 못함을 알고 채택하지 않음.<br>
    <blockquote> C.Szegedy, A.Toshev, and D.Erhan. Deep neural networks for object detection. In NIPS, 2013.</blockquote>
  </li>
  <li>
    <b>Sliding Window</b><br>
    &nbsp;R-CNN은 합성곱 층이 5개인 구조여서, 매우 큰 윈도우 (195\*195 pixels)와 Strides (32\*32 pixels)로는 정확한 localization 이 힘들기 때문에 채택하지 않음.<br>
  </li>
  <li>
    <b>Region Proposals</b><br>
    &nbsp;`Selective Search` 를 채택 함.<br>
    <blockquote> C. Gu, J. J. Lim, P. Arbelaez, and J. Malik. Recognition using regions. In CVPR, 2009.</blockquote>
  </li>
</ol>
<br>
</li>
<li>
<h3>Feature Extraction</h3>
<p> CNN(AlexNet) 을 활용하여 각 region proposal에서 4096 차원의 feature vector을 추출한다.<br><br>
 feature vector을 얻기 위해, region proposal을 5개의 합성곱층과 2개의 완전 연결 계층으로 이루어진 CNN(AlexNet)의 input size인 (227*227 pixels)에 맞춰야 한다.<br>
 이를 위해, 어떠한 비율의 box든 input size로 변형(warping)을 해야하는데, 객체 영역만 tight 하게 자른 box가 아닌 p pixels 만큼 여유를 두고 자른 박스를 warping 합니다.(논문에서는 p = 16 을 사용하였다.)<br></p>
<blockquote>
<h4>CNN( AlexNet ) 참고 논문</h4>
<p>C.Szegedy, A.Toshev, and D.Erhan. Deep neural networks for object detection. In NIPS, 2013.<br><br></p>
</blockquote>
</li>
<li>
<h3>Test-time detection</h3>
<p> 테스트 단계에서 CNN 을 통하여 얻은 region의 feature를 SVM을 사용하여 각 클래스 마다 점수를 매긴다.<br>
 한 이미지에서 이렇게 점수를 매긴 region을 각 클래스 별 독립적으로 <code>greedy non-maximum suppression</code>을 수행한다.</p>
<blockquote>
<h4>NMS (Non-Maximum Suppression)</h4>
<div style="text-align: center;">
 <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; ">
      <a class="gatsby-resp-image-link" href="/static/951e076e741db6163a32222cf6ca6bd1/c4451/NMS_img.png" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 76.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABYlAAAWJQFJUiTwAAAEM0lEQVQ4yx3S6U+TBwDA4Tf7smQfl2zJkmXLFpcZ45G5TAyMMWWigYJgwZVSWoUWrRwVwULBImcLWtpSQAFLaQEFsTCsoIi4iVTmJuKBmdiIqBxKUHCEeMyx37I9f8MjdF3wIEnZhsawi3SzEn3TLuzdh3k69YT/vHnzF2//XuLazSFiU6Wo9EloylUYW5ScvaLgjxETS28HWFqCFwsLCFWNZt79UuCzDe+zYvuHhGk+R6oJocjm4sHcOJXuGn4e8jJ0+yKbZQIx6ndIOPge8gMfUFb5BQWH9nNnvJSf+quxnz6O4Gxx4BccQKQ8nHUxKxCL12LNM6DK1lFalkhsUgTuvrPMPe9nr3YVO9WRFNs+IVK6HLtJhjKjBLszFKt1JeaGfIT6E8f4OmgNCWlRxGXHsiV8A8roUBIVSkoTNqHNjuTyb16mn1xkf+6nGE1BdHR/TGbWKow5K9Hro2kwrMZ+ZDUtHRUIfZdOkZ4ZgsW4A6teTn2phrjvVmHOTUYdswFH3V5G711nxHeLkqJg2lzfc7LOn9MuMXui1mA9ICEnOYBWp5Sr3lMIvuEBzh3L59eOSlLEwZxvKMaaLsFTm4d5v5w2ezXt/aO4vQ9oqT3Kjd5iLPp1nD8uwVGgxFWcgU0v5UKThruDfQiPRq9zqc3K4Ok6aos1tFp1WHRJmHVKWityaDVn4hv2sjj7kK62Znp+OcnF9m/pdYfjNEs4WrKNTkc8HnsKA10nEV7MP2ds7C4Tj8eYnZ1gcvoeczPjvJmf4tXCc+YX/+QV8Iol+kce0nF1hhfPHjMxeZ+5KR+LM2Mszs+wMD/H65eLCE3tTtaKVhCm3ohoXyCJFhHGI0kM9ff//5Cb1+DMCcZsBURH+bM+QcTWjCCSTGJqbBIuNR7i9aMRXv4DE0+nEZo7HSwL/IiA6NV8E7+MaPV60pKlqLKMtHs7KctQcK0yh0m3A4U0gKjdPxCs3kxoYiD70uKRphpoPl6N/qiNuo4qBE+3h03hInYmywnbE0GoKIiK7HTSdVoqdeGod2yk/Uovsy9fE71DQX5RHqoCHSFhfthzdrMvV0+DLphCRSA2RzlCZ88pQiL9UWvFJBTIEMVsITHkKxJjYymRB6E/sJXfh/uYfjJFfMKPaA/uJs6QymbZFnK2LidLHo5V5ochKwJPTz2Cd8BDeaGMausuCvbGUGPLJW+7P25TCqlxobhqS5h5dAvfvdvUWzNx2bWkamQUmdMwKvxpL5SSJougqroc341uhPs3vfTVF3G+zYhE5EfF4UwsaTG4jCmYs1U0m/OZHL3O08c+ztUdpLetkDDxRrRFSRzRyanNU1Gq3YO9/DCjg2cQJsbuMNjVwOUeJ05nEU5HFbUWE3XWQ7gbHbQ7qhi/O8z8s2kGu1xcPldPvl2HoaaCCpMNS5kZe10jrQ12bnnP8i9X0SOCkvx2rgAAAABJRU5ErkJggg=='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="NMS img" title="" src="/static/951e076e741db6163a32222cf6ca6bd1/5a190/NMS_img.png" srcset="/static/951e076e741db6163a32222cf6ca6bd1/772e8/NMS_img.png 200w,
/static/951e076e741db6163a32222cf6ca6bd1/e17e5/NMS_img.png 400w,
/static/951e076e741db6163a32222cf6ca6bd1/5a190/NMS_img.png 800w,
/static/951e076e741db6163a32222cf6ca6bd1/c1b63/NMS_img.png 1200w,
/static/951e076e741db6163a32222cf6ca6bd1/c4451/NMS_img.png 1450w" sizes="(max-width: 800px) 100vw, 800px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
 </div>
<br>
object detector가 예측한 bounding box 중에서 정확한 bounding box를 선택하도록 하는 기법<br><br>
</blockquote>
<blockquote>
<p>N. Bodla, B. Singh, R. Chellappa and L. Davis, Soft-NMS — Improving Object Detection with One Line of Code, in 2017</p>
</blockquote>
<h4>Run-time analysis</h4>
<p> 두가지 특징이 detection을 빠르고 효율적으로 만든다.</p>
<ol>
<li>모든 클래스에서 CNN의 parameters를 공유한다.</li>
<li>CNN을 통해 얻은 feature vectors(4k-dimention) 들은 다른 일반적인 접근법들보다 차원이 낮다.</li>
</ol>
</li>
<li>
<h3>Training</h3>
<h4>Supervised pre-training</h4>
<p> CNN(AlexNet)을 거대한 보조 data-set인 ILSVRC2012(이미지만 있고 bounding box 가 없는)로 이미지 분류를 위한 pre-training을 한다.<br><br></p>
<h4>Domain-specific fine-tuning</h4>
<p> CNN이 warp된 proposal window(domain)에 잘 작용하기 위해, warp된 region proposal들 만 사용하여 stochastic gradient descent(SGD) 알고리즘으로 CNN parameters 를 훈련시켰다.<br><br></p>
<h4>Object category classifiers</h4>
<p> 객체를 분류할때, 찾으려는 객체가 완전히 들어와 있는 box는 positive 이고 객체가 조금이라도 들어와 있지 않는 box는 negative 이다.  그렇다면 객체가 일부 들어간 box는 positive 일까 negative 일까?<br>
 이에 관하여 IoU 임계값이 {0,0.1,...,0.5}중 0.3 인 것이 결과가 가장 좋아 0.3이상인 것은 positive 아닌것은 negative으로 하였다.<br>
 CNN을 통해 features가 추출되고 training labels 가 주어지면 linear SVM을 각 클래스마다 훈련시켜야 한다.<br>
 이때 training data가 너무 많아 메모리가 꽉 차는 현상을 막기 위해 <code>hard negative mining method</code>를 채택하였다.</p>
<blockquote>
<h4>hard negative mining</h4>
<p> positive example 과 negative example 을 균형적으로 학습시키 위한 기법.<br>
 negative examples 가 있으면 confidence score 순으로 샘플을 선정 후, random하게 선정한 positive examples 를 갖고 하나의 mini-batch로 만들어 사용하는 방법.<br>
 일반적으로 negative examples의 갯수가 훨씬 많은데, 그중 일부만 사용하여 메모리의 사용량을 줄일 수 있다.<br><br></p>
</blockquote>
<br>
</li>
</ul>
<h2>Visualization, ablation, and modes of error</h2>
<ul>
<li>
<h3>Visualizing learned features</h3>
<p> CNN의 첫번째 계층은 경계와 보색을 찾아준다. 두번째 계층부터는 이해하기가 힘든데, 직관적으로 알아보려고 한다. 그 방법은 하나의 feature를 선택하여 마치 객체 탐지기 처럼 사용하는 것이다.<br>
 방법은 다음과 같다.<br></p>
<ol>
<li>많은 region proposals에서 feature들의 활성화를 계산한다.</li>
<li>활성화가 큰 순서대로 정렬 한다.</li>
<li><code>non-maximum suppression</code>을 수행한다.</li>
<li>높은 점수의 region을 확인한다.</li>
</ol>
<p><br><br></p>
<div style="text-align: center;">
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; ">
      <a class="gatsby-resp-image-link" href="/static/71a540217695ba3d0aa68350844f97e7/3d22e/R-CNN_figure4.png" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 39.49999999999999%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAACF0lEQVQozwXB207aAACA4T6XyZLdLF5sUZe4AaJMkBbwAJSCFCgtbTkXW4uiqMzjmBFN1My57JBdzN0s2c2e6N/3CU+fvzI5O+ZqfEyvXuVurOH7HqO9bSYjj25dp6FKTC5Pebi/4+JkwIezHR5vr7kauZwPHD4NdMaOyvH7E4TLPZdyJoalFyllRHp6hIpRoV4ts23IqLEg88+mkMUYu2aWohTGUNaxagayuEKv69AqStSkV5z2TYSr6xOUbBR1M02xIJJLLqMsvKaSimMrKRIzz9HD03h2mp4cwVdWaWfT5FejDAce5+NTMutxlJUA95dHCN1Gk3wmR1NTUTeT1FJB5JcvkBMRKmtxDswsN8MGfj2JXy5x1Pdp5iWMtRD6dhunY1Ep5UiGZ9h1NYR9zyM4N0M0HGYpFCCfWCQcjdLuWLQ0kb5V4v7uFjEZwlDWEOdmscUAf38PmZ6eQlMknr498vjwwMfxOcKPn1/oOm1arQa+59Cp67hOGzn1jsjCPK7TY+RuUU/n6TQb7O7v4Xk9jjydZFrC2x9wM5kwvhjz688/hOHIR4wG6VYLHHg2lqZiyXFay7NYSyE6eYWermFKcVKRRfK5DWxNQcsmMJMiw50hh4d9jPImvucj2NUaGyshBo0MviHTNA2qiQBuNEQ3k6KpFWiXsnRtlVjgDQtv3+BvmVz4Ot+bBbT1VXaMOq5ps9W0+Q8a1Y9El3l7WgAAAABJRU5ErkJggg=='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="R CNN figure4" title="" src="/static/71a540217695ba3d0aa68350844f97e7/5a190/R-CNN_figure4.png" srcset="/static/71a540217695ba3d0aa68350844f97e7/772e8/R-CNN_figure4.png 200w,
/static/71a540217695ba3d0aa68350844f97e7/e17e5/R-CNN_figure4.png 400w,
/static/71a540217695ba3d0aa68350844f97e7/5a190/R-CNN_figure4.png 800w,
/static/71a540217695ba3d0aa68350844f97e7/c1b63/R-CNN_figure4.png 1200w,
/static/71a540217695ba3d0aa68350844f97e7/29007/R-CNN_figure4.png 1600w,
/static/71a540217695ba3d0aa68350844f97e7/3d22e/R-CNN_figure4.png 2010w" sizes="(max-width: 800px) 100vw, 800px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span><br>
  <b>Figure 4: 5번째 pooling 후 높은 점수 의 후보 영역</b>
</div>
<br>
나열된 점을 dog로 분류하고, 반사된 표면 등 분류된 결과를 볼 수 있다.<br>
다음 결과로 보아 network는 약간의 class-tuned features와 함께 모양, 질감, 색상 및 재료 속성이 분포된 표현을 학습하는것으로 보인다.<br>
<br>
</li>
<li>
<h3>Ablation studies</h3>
<blockquote>
<h4>Ablation studies</h4>
<p>특정 요소가 전체 시스템에 어떤 영향을 주는지 확인하고 싶을때 해당 요소를 제거한 시스템과 비교해보며 확인하는 분석 기법.<br><br></p>
</blockquote>
<div style="text-align: center;">
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; ">
      <a class="gatsby-resp-image-link" href="/static/3a9a689dd33cf980f4635509de1f43fe/5b503/R-CNN_table2.png" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 27%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAtUlEQVQY001QQQ6EIAz0/w/UBYQICgLRA172OJtpUrOHSWlnOm2ZYoyw1mKMgZQS9n1HzhnHcbyxlCKRHDXMCfKK8zxBr0kNnucREYnWGnrv8qYR83/uui4BNcxrre8AMXTWobcuGxAU6IbM1VibyOtQ1egFU/ABs50R9wjzMViWBd57+QbnHIwxWNdVYghBaow8b9s20aqOvVOKCS47PN+Bkgtqq7jv+z1ZN+FWeiZ5BWvUKX6nwG9RuO+kcgAAAABJRU5ErkJggg=='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="R CNN table2" title="" src="/static/3a9a689dd33cf980f4635509de1f43fe/5a190/R-CNN_table2.png" srcset="/static/3a9a689dd33cf980f4635509de1f43fe/772e8/R-CNN_table2.png 200w,
/static/3a9a689dd33cf980f4635509de1f43fe/e17e5/R-CNN_table2.png 400w,
/static/3a9a689dd33cf980f4635509de1f43fe/5a190/R-CNN_table2.png 800w,
/static/3a9a689dd33cf980f4635509de1f43fe/c1b63/R-CNN_table2.png 1200w,
/static/3a9a689dd33cf980f4635509de1f43fe/29007/R-CNN_table2.png 1600w,
/static/3a9a689dd33cf980f4635509de1f43fe/5b503/R-CNN_table2.png 1976w" sizes="(max-width: 800px) 100vw, 800px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span><br>
  <b>Table 2: PASCAL VOC 2007에서의 detection average precision(%)</b>
</div>
<br>
&nbsp;R-CNN의 CNN은 AlexNet으로 5계층의 합성곱층과 2계층의 완전연결계층으로 이루어져 있다.<br>
&nbsp;CNN의 마지막 풀링층을 pool5, 완전연결계층 2계층을 각각 fc6, fc7이라 명명하자.<br>
<h4>Performance layer-by-layer, without fine-tuning</h4>
<p> 먼저 fine-tuning을 하지 않았을 때 결과를 비교해 보기 위해 ILSVRC 2012 데이터로만 사전훈련한 CNN을 사용하여 분석하였다.<br>
 위 table 의 1-3행의 결과를 보면, PASCAL VOC 데이터에 fine-tuning을 하지않은 경우 fc7의 결과보다 fc6의 결과가 더 좋은것을 볼 수 있다. 이는, CNN의 매개변수의 29%인 약 1680만개를 mAP 저하없이 제거 할 수 있음을 의미한다.<br>
 이보다 더 놀라운 점은 pool5까지만 있는 네트워크에서도 pool5가 6%만큼의 features를 계산하지 않음에도 불구하고 꽤나 좋은 결과를 보여줬다는 것이다.
 이 결과로 CNN의 표현력의 상당부분은 합성곱층에서 온다는것을 알 수 있다.</p>
<h4>Performance layer-by-layer, with fine-tuning</h4>
<p> fine-tuning 을 했을때 결과를 비교해 보자. fc6 와 fc7의 결과가 pool5까지만 했을때 보다 훨씬 좋은것을 볼 수 있다.<br>
 이를 통해 대부분의 성능적 향상은 domain-specific non-linear clssifers(fc6, fc7)을 학습함으로서 얻을 수 있다는 것을 알 수 있다.<br>
<br></p>
</li>
<li>
<h3>Network architectures</h3>
<div style="text-align: center;">
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; ">
      <a class="gatsby-resp-image-link" href="/static/e018a2b34f01780171091763fcbc2324/e53e8/R-CNN_table3.png" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 13.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAe0lEQVQI101PSQpFIQzz/hd04Tw9Zz1CPykIfxESk5RWoZSiey/13qmUwtxaozEG7b1prcX6+f8MH7rWynzOISGlpBACee/JGMOcUmLPOcdvLAJbaynGyIAHoIsMfa01iRdiQ86ZNTbigu/7eOBdhRw852TgemTovN/9APpd3Q4TAsUQAAAAAElFTkSuQmCC'); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="R CNN table3" title="" src="/static/e018a2b34f01780171091763fcbc2324/5a190/R-CNN_table3.png" srcset="/static/e018a2b34f01780171091763fcbc2324/772e8/R-CNN_table3.png 200w,
/static/e018a2b34f01780171091763fcbc2324/e17e5/R-CNN_table3.png 400w,
/static/e018a2b34f01780171091763fcbc2324/5a190/R-CNN_table3.png 800w,
/static/e018a2b34f01780171091763fcbc2324/c1b63/R-CNN_table3.png 1200w,
/static/e018a2b34f01780171091763fcbc2324/29007/R-CNN_table3.png 1600w,
/static/e018a2b34f01780171091763fcbc2324/e53e8/R-CNN_table3.png 1982w" sizes="(max-width: 800px) 100vw, 800px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span><br>
  <b>Table 3: PASCAL VOC 2007에서의 두개의 다른 CNN 구조의 detection average precision(%)</b><br>
  T-Net = AlexNet / O-Net = VGG16
</div>
<br>
&nbsp;위의 결과로 볼 수 있듯, AlexNet 대신 VGG16을 사용하면 성능이 더 좋아집니다. 하지만 연산속도가 7배 느려진다는 단점이 있다.<br>
<br>
</li>
<li>
<h3>Detection error analysis</h3>
<blockquote>
<p>D. Hoiem, Y. Chodpathumwan, and Q. Dai. Diagnosing error in object detectors. In ECCV. 2012.</p>
</blockquote>
<p> 저자의 방법에 error mode 를 구하고, fine-tuning 이 error mode를 어떻게 변화시키는지 그리고 저자의 error types 이 DPM과 비교하여 알아보기 위하여 위 논문에서 제시하는 analysis tool을 사용하였다.<br>
<br></p>
<div style="text-align: center;">
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; ">
      <a class="gatsby-resp-image-link" href="/static/3431a989622ee2bf2f4663e21e49ed0c/587b0/R-CNN_figure5.png" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 75.99999999999999%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABYlAAAWJQFJUiTwAAAEKklEQVQ4yyXS/U+UBQDA8WdrqzVnW86trVq1Vi3NWi7LcsvCAkHtBA6lUsA0S1HLt7DLNFOylyUeB17AyaGIpLzIiYCIiLomJMrhAff23D13zx3HcbzeIXfHS9q3Nf+B7y+frwAwGY0S8AWwOoz4BjtxyT2MBYeIRqO4JQ9Ot4nAaA+yx0Kfz00kEsVuN+PxG+kb6EaSLLgkKxMTUYSJqShtzTepzTzB5V1armrTsdx6Cs9AAlK3lZavT9O4W8P1MiXmzmeQfK8hO0XO79Rzcd8+2muXIIpPInpeJhyREMJ3Rzl7vo33FqvRrSzgcoqexrT1iH8uw95j5ZdELZVJhTSt0lG/YSu3te/T53bQkKGnUVlMzao8ruxKoav0OcIhC0I0HOJcfTsz38zj2UV57E3SUpekp313BR13RGYtymfuolwOJmupU56g5bNyfE4Z3ZoCjiceozmtmEspp7mUqiXk8SOMhUa4UN/K9qxy4jJKmbUwn5UxR6n7rgqj0cEu1VlWfF7K42/lEbtETd56PZJNZq+qjHVbThIfo+FwUj4164oJ9Q4jjI6N0dp8mZuVhaR+Vc3MeWoeflVN7NpyzEYTJkMhm7838Oico8yYr+H5D4qwWUTazuTx7c8GhDlqHntDw+uLNXjcgwj/KzslK1daKjlacJGs7Gp27C9Ho7+KTbRx44aBfN1FvjlUTdahCrLV9TglJ3+31aI72UDWoWr2ZFei+s2A3Bt4ELz/LwyOTGMXZXzeALLUz1T0HlPT0wRCEeyyjN8/iMfVz9hohOjEBP7RMA7Zi683gOz0M9QfZHJyCmFqGtxSC9aOOLpvLcXUHY9JfAd37zb83h56zq/G0qDAYlJgEhdjdirp73PQVZuKtVlBt3k53VIMJutSwmEZYSgYxNjURMfGRJwbF+DZ8iIOzQykzvk4unq4lpSFNWk50vq5uPbNxtH0NF6XhfbUdBzJC/FsfgH3wSewN8xiPGxBGA+HaKm/yYG44xgS8+lS7sTzYQxDqnW0d9pQxBaiSyykLfVXzAkZeDOSkUUHZWtLuKTMxajMQlyWgmf1UiI+F8Ld0AhVda0oNpXy8ZoS9iiKaEz5EZ/qB2532FBklrNijZ70+D84piygddMR7FaJrdtPcSTzFDnJOgyfamnP2E/Y60UYCY7yV9N1rpWdIWlbBQ/NzWHeAg0HM6uwdNpoO1PBF3vPIbyUw+z5apZ/pEeyu2ksOcX2n2p4ZM4RXnlbwyfxRQx4RxDu3YfuO23UV+Ww40ANCeklvJtayAZVDV1dRlou5KI6XENCWgnxacUovizFbO7hal0u2b9XEpd2gth0PbEZx7E6eh9sM/3PPfoHhnGKVny9ErJkYyIcJBKNMjAcwiFa6fO58LjsjIeGiEQijITGcTjs9PVKeNx2gsP9TE1O8h/ug39ZOLGaigAAAABJRU5ErkJggg=='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="R CNN figure5" title="" src="/static/3431a989622ee2bf2f4663e21e49ed0c/5a190/R-CNN_figure5.png" srcset="/static/3431a989622ee2bf2f4663e21e49ed0c/772e8/R-CNN_figure5.png 200w,
/static/3431a989622ee2bf2f4663e21e49ed0c/e17e5/R-CNN_figure5.png 400w,
/static/3431a989622ee2bf2f4663e21e49ed0c/5a190/R-CNN_figure5.png 800w,
/static/3431a989622ee2bf2f4663e21e49ed0c/587b0/R-CNN_figure5.png 970w" sizes="(max-width: 800px) 100vw, 800px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span><br>
  <b>Figure 5: object characteristics 에 대한 sensitivity</b><br>
</div>
<br>
<div style="text-align: center;">
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; ">
      <a class="gatsby-resp-image-link" href="/static/e9437f67845bc47732ecb7df2381ca82/c9d77/R-CNN_figure6.png" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 20.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAwUlEQVQY0z2O667DIAyD+/7POY0C5Q6hsGrfEehoP6I4jhP7mHOSUsJ7z+Xcxr33PTvnMMYQQtj8ZS1Ga06lsNb+7tZ+9VWHPk9qSjTvKdZSYiQuHAJRa4rWZOe2uDpHtJasFOm6aCJ8v1/mGDzPwxiDQ73f9FKQGOkpITkTnGOK8BmDu1akFIL3PPfNZ06eOWmLW8mN2Ybyb3asr6UUYoyEGMk5IyLklDb2IVBrpbW2NUu709ZKF+EyBqs16vXa/Q/40TFhgy3rAAAAAABJRU5ErkJggg=='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="R CNN figure6" title="" src="/static/e9437f67845bc47732ecb7df2381ca82/5a190/R-CNN_figure6.png" srcset="/static/e9437f67845bc47732ecb7df2381ca82/772e8/R-CNN_figure6.png 200w,
/static/e9437f67845bc47732ecb7df2381ca82/e17e5/R-CNN_figure6.png 400w,
/static/e9437f67845bc47732ecb7df2381ca82/5a190/R-CNN_figure6.png 800w,
/static/e9437f67845bc47732ecb7df2381ca82/c1b63/R-CNN_figure6.png 1200w,
/static/e9437f67845bc47732ecb7df2381ca82/29007/R-CNN_figure6.png 1600w,
/static/e9437f67845bc47732ecb7df2381ca82/c9d77/R-CNN_figure6.png 1964w" sizes="(max-width: 800px) 100vw, 800px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span><br>
  <b>Figure 6: top-ranked false positive(FP) types 의 분포</b><br>
</div>
<br><br>
</li>
<li>
<h3>Bounding-box regression</h3>
<p> error analysis 에 기초하여, 저자는 localization error를 줄이기 위해 간단한 method를 구현하였다.<br>
 <code>deformable part model (DPM)</code>에 적용된 bounding-box regression 에 영감을 받아, selective search 의 region proposals 에 대한 pool5의 feature이 주어지면 새로운 detection window를 예측하기 위해 선형회귀 모델을 훈련한다.<br></p>
<blockquote>
<p>bounding-box regression 에 대한 자세한 사항은 Appendix C 참고.</p>
</blockquote>
<p> Table1, Table2, Figure5를 보면 이러한 간단한 접근이 많은 mislocalized detection들을 해결 하며 mAP를 3~4 point 향상 시키는 것을 볼 수 있다.<br>
<br></p>
</li>
<li>
<h3>Results on PASCAL VOC 2010-12</h3>
<div style="text-align: center;">
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; ">
      <a class="gatsby-resp-image-link" href="/static/e018a2b34f01780171091763fcbc2324/e53e8/R-CNN_table3.png" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 13.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAe0lEQVQI101PSQpFIQzz/hd04Tw9Zz1CPykIfxESk5RWoZSiey/13qmUwtxaozEG7b1prcX6+f8MH7rWynzOISGlpBACee/JGMOcUmLPOcdvLAJbaynGyIAHoIsMfa01iRdiQ86ZNTbigu/7eOBdhRw852TgemTovN/9APpd3Q4TAsUQAAAAAElFTkSuQmCC'); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="R CNN table3" title="" src="/static/e018a2b34f01780171091763fcbc2324/5a190/R-CNN_table3.png" srcset="/static/e018a2b34f01780171091763fcbc2324/772e8/R-CNN_table3.png 200w,
/static/e018a2b34f01780171091763fcbc2324/e17e5/R-CNN_table3.png 400w,
/static/e018a2b34f01780171091763fcbc2324/5a190/R-CNN_table3.png 800w,
/static/e018a2b34f01780171091763fcbc2324/c1b63/R-CNN_table3.png 1200w,
/static/e018a2b34f01780171091763fcbc2324/29007/R-CNN_table3.png 1600w,
/static/e018a2b34f01780171091763fcbc2324/e53e8/R-CNN_table3.png 1982w" sizes="(max-width: 800px) 100vw, 800px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span><br>
  <b>Table 1: VOC 2010 test set 에 대한 Detection average precision(%)</b><br>
</div>
<br>
</li>
<li>
<h3>Results on ILSVRC2013 detection</h3>
<div style="text-align: center;">
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; ">
      <a class="gatsby-resp-image-link" href="/static/e018a2b34f01780171091763fcbc2324/e53e8/R-CNN_table3.png" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 13.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAe0lEQVQI101PSQpFIQzz/hd04Tw9Zz1CPykIfxESk5RWoZSiey/13qmUwtxaozEG7b1prcX6+f8MH7rWynzOISGlpBACee/JGMOcUmLPOcdvLAJbaynGyIAHoIsMfa01iRdiQ86ZNTbigu/7eOBdhRw852TgemTovN/9APpd3Q4TAsUQAAAAAElFTkSuQmCC'); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="R CNN table3" title="" src="/static/e018a2b34f01780171091763fcbc2324/5a190/R-CNN_table3.png" srcset="/static/e018a2b34f01780171091763fcbc2324/772e8/R-CNN_table3.png 200w,
/static/e018a2b34f01780171091763fcbc2324/e17e5/R-CNN_table3.png 400w,
/static/e018a2b34f01780171091763fcbc2324/5a190/R-CNN_table3.png 800w,
/static/e018a2b34f01780171091763fcbc2324/c1b63/R-CNN_table3.png 1200w,
/static/e018a2b34f01780171091763fcbc2324/29007/R-CNN_table3.png 1600w,
/static/e018a2b34f01780171091763fcbc2324/e53e8/R-CNN_table3.png 1982w" sizes="(max-width: 800px) 100vw, 800px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span><br>
  <b>Figure 3: ILSVRC2013 detection test set 에 대한 mAP</b><br>
</div>
<br>
</li>
</ul>
<h2>The ILSVRC2013 detection dataset</h2>
<p>ILSVRC2013 dataset은 PASCAL VOC dataset보다 균일하지 않다. 따라서 데이터 선택에 중요성을 요구한다.</p>
<ul>
<li>
<h3>Dataset overview</h3>
<p>ILSVRC2013 은 다음과 같이 분류됩니다.<br></p>
<ul>
<li><b>val</b> (20,121 개) &#x26; <b>test</b> (40,152 개)<br>
 검증 데이터와 테스트 데이터는 같은 이미지 분포로 이루어져 있고 모든 클래스(200 개)에 대해 bounding box 와 labeled가 되어져 있다.(annotated 됨)</li>
<li><b>train</b> (395,918 개)<br>
 훈련 데이터는 완전히 annotated 되어 있지 않다.<br></li>
</ul>
<br>
<p> 훈련 데이터는 완전히 annotated 되어 있지 않기 때문에 <code>hard negative mining</code>을 사용 할 수 없다.<br>
 이를 해결하기 위해 검증 데이터를 동일한 비율의 class로 val1과 val2로 같은 양으로 나눈다. 그리고 val1 과 훈련 데이터의 일부를 사용하여 positive examples로 활용한다.<br>
<br></p>
</li>
<li>
<h3>Region proposals</h3>
<p> ILSVRC 2013에서도 PASCAL VOC에서와 같이 Selective search 가 val1, val2, test 이미지 각각(훈련 데이터는 빼고)에 fast mode 로 적용하는 방식으로 region proposals를 수행한다.<br>
 한가지 다른점이 있다면, selective search는 scale invariant 하기 때문에 이미지의 크기(해상도)에 따라 region 생성의 수에 영향을 미치는데, ILSVRC 이미지는 크기가 일정하지 않다는 것이다.<br>
 이를 위해 selective search를 수행하기 전 각 이미지 마다 500 pixels로 너비를 고정 하였다.<br>
<br></p>
</li>
<li>
<h3>Training data</h3>
<p> 훈련 데이터는 다음과 같이 만들었다.<br></p>
<ul>
<li><b>훈련 데이터</b> = <b>val1 의 <u>모든 selective search 와 ground-truth box</u></b> + <b>train 의 <u>각 class당 N개의 ground-truth box (만약 N개보다 적을경우 모든 box를 사용)</u></b><br></li>
</ul>
<p> 저자는 이를 val1 + trainN 라 명명 한다.<br><br>
 훈련 데이터는 R-CNN에서 다음 3가지 절차를 수행하는데 필요하다.</p>
<ol>
<li><b>CNN fine-tuning</b> : PASCAL에서 훈련한 것과 같이 val1과 trainN 으로 5만번의 SDG iteration을 수행하여 fine-tuning</li>
<li><b>SVM 검출기(detector) training</b> : val1과 trainN의 모든 ground-truth boxs를 사용. val1에 Hard negative mining 을 사용하여 5000개의 이미지를 선별. train는 완전히 annotated 되지 않기 때문에 negative examples을 선별하지 않음.</li>
<li><b>bounding-box regressor training</b> : val1 만 사용하여 훈련</li>
</ol>
<p><br><br></p>
</li>
<li>
<h3>Validation and evaluation</h3>
<p> 결과를 평가 서버에 제출하기 전, 훈련 데이터 사용의 검증과 위의 데이터를 사용하여 훈련한 CNN fine-tuning과 bounding-box regressor의 영향을 val2를 사용하여 검증하였다.<br>
 추가적인 tuning 없이 ILSVRC 에서 R-CNN의 결과를 확인하기 위한것 이기 때문에 모든 시스템의 hyperparameter은 PASCAL에서 사용한것과 똑같이 고정하였다.<br>
 val2에서 가장 좋은 결과를 보인 모델을 선택하여, bounding-box regression이 있는 모델과 없는 모델을 ILSVRC2013 평가 서버에 올렸다.<br>
<br>
제출을 위해 사용된 training-set은 다음과 같다.</p>
<ul>
<li><b>SVM</b> : val + train1k</li>
<li><b>bounding-box regressor</b> : val</li>
<li><b>CNN</b> : val1 + train1k</li>
</ul>
<p><br><br></p>
<p>CNN은 fine-tuning과 feature 계산을 반복 하지 않기 위해 val1 + train1k를 사용하였다.<br>
<br></p>
</li>
<li>
<h3>Ablation study</h3>
<div style="text-align: center;">
  <span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; ">
      <a class="gatsby-resp-image-link" href="/static/4f3811b395d8469b47f197c834727fc0/06868/R-CNN_tabel4.png" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 21%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAtElEQVQY0z2PxwqFQBRD5/+/TUHdiiD23nshjwR8iyG3zj0xx3EgDEMURQHG0zSh73vs+654nmes64phGHCep3rXdUk537at8nEcsW0bTFmW8DwPjuMgyzJ90DSNlEt8X63rOkRRhLqukSSJIOI4Vs7dPM9hmFiWBdu2VSQVr5KGV0nHyyQkUVVV6hGELj7lMe6a933hui583//bJc1nb1mWP+HzPKKiBkEgq4S47xtpmmr+B2SKLmsKyTJfAAAAAElFTkSuQmCC'); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="R CNN tabel4" title="" src="/static/4f3811b395d8469b47f197c834727fc0/5a190/R-CNN_tabel4.png" srcset="/static/4f3811b395d8469b47f197c834727fc0/772e8/R-CNN_tabel4.png 200w,
/static/4f3811b395d8469b47f197c834727fc0/e17e5/R-CNN_tabel4.png 400w,
/static/4f3811b395d8469b47f197c834727fc0/5a190/R-CNN_tabel4.png 800w,
/static/4f3811b395d8469b47f197c834727fc0/c1b63/R-CNN_tabel4.png 1200w,
/static/4f3811b395d8469b47f197c834727fc0/29007/R-CNN_tabel4.png 1600w,
/static/4f3811b395d8469b47f197c834727fc0/06868/R-CNN_tabel4.png 1974w" sizes="(max-width: 800px) 100vw, 800px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span><br></div>
<p><b>Table 4: data usage choices, fine-tuning, bounding-box regression 에 관한 ILSVRC2013 ablation study </b><br></p>
</div>
<br>
</li>
<li>
<h3>Relationship to OverFeat</h3>
<p>R-CNN 과 OverFeat은 다음과 같은 차이점을 제외하면 매우 비슷하다. <br></p>
<table>
<thead>
<tr>
<th>R-CNN</th>
<th></th>
<th>OverFeat</th>
</tr>
</thead>
<tbody>
<tr>
<td>selective search</td>
<td>영역추정</td>
<td>multi-scale pyramid</td>
</tr>
<tr>
<td>per-class BB regressor</td>
<td>BB</td>
<td>single BB regressor</td>
</tr>
</tbody>
</table>
<br>
OverFeat은 R-CNN보다 성능은 떨어지지만 9배 더 빠르다. 이러한 속도적 이점은 sliding windows 기법은 이미지 warping이 필요 하지 않기 때문이다.<br>
<br>
</li>
</ul>
<h2>Conclusion</h2>
<p>Abstract 에서 말한것과 같이,<br></p>
<ol>
<li>region proposals 를 통한 객체탐지</li>
<li>labeled 된 훈련 데이터가 부족할때 supervised pre-training 과 domain-specific fine-tuning 을 통해 성능을 향상<br></li>
</ol>
<p>=> labeled되지 않은 많은 데이터로 supervised pre training을 하고 (image classification) 그리고 나서 적은 labed된 영역을 가지고 fine-tuning한다 (detection).
<br></p>
<p>을 통하여 좋은 결과를 보였다.</p></div></div><a class="main_a mainColor" style="font-size:var(--font-sm);text-decoration:none" href="/blog/"><b>➯ to list of blog posts</b></a></div></main><footer style="margin-top:100px;font-size:var(--font-sm);color:var(--color-secondary)">© 2022 by <!-- -->Jun&#x27;s Blog</footer></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/blog/rcnn-review/";/*]]>*/</script><!-- slice-start id="_gatsby-scripts-1" -->
          <script
            id="gatsby-chunk-mapping"
          >
            window.___chunkMapping="{\"app\":[\"/app-ef97999eb50fbcecc03f.js\"],\"component---src-pages-404-tsx\":[\"/component---src-pages-404-tsx-cd8845158377fe778e85.js\"],\"component---src-pages-about-tsx\":[\"/component---src-pages-about-tsx-26d93325668359dd0425.js\"],\"component---src-pages-blog-tsx\":[\"/component---src-pages-blog-tsx-e55e8b123bff96c711d1.js\"],\"component---src-pages-gatsby-guide-tsx\":[\"/component---src-pages-gatsby-guide-tsx-2b4fdca2d9f658f34328.js\"],\"component---src-pages-index-tsx\":[\"/component---src-pages-index-tsx-d97fbfb377a955668dd2.js\"],\"component---src-pages-page-2-tsx\":[\"/component---src-pages-page-2-tsx-da136b020e212fc70d67.js\"],\"component---src-pages-using-ssr-tsx\":[\"/component---src-pages-using-ssr-tsx-e97a9f6d219f23780e1f.js\"],\"component---src-pages-using-typescript-tsx\":[\"/component---src-pages-using-typescript-tsx-6f6cdaa9495e506192df.js\"],\"component---src-templates-post-template-tsx\":[\"/component---src-templates-post-template-tsx-683c6e7d73c2f86203f0.js\"]}";
          </script>
        <script>window.___webpackCompilationHash="76c17966566945ec81b9";</script><script src="/webpack-runtime-123d8a615b39dd909025.js" async></script><script src="/framework-6e68b7056956344bfd29.js" async></script><script src="/app-ef97999eb50fbcecc03f.js" async></script><!-- slice-end id="_gatsby-scripts-1" --></body></html>