{"componentChunkName":"component---src-pages-blog-tsx","path":"/blog/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"html":"<br>\r\n<b>\n<p>객체 탐지 평가기준<br></p>\n<ol>\n<li>얼마나 잘 탐지 하였는지 평가 (탐지 정확성 - 분류 &#x26; 위치탐지)</li>\n<li>얼마나 빨리 탐지 하였는지 평가 (탐지 속도)</li>\n</ol>\n</b>\r\n<br>\n<h2>1) 얼마나 잘 탐지 하였는지 평가 (탐지 정확성 - 분류 &#x26; 위치탐지)</h2>\n<h3><U>분류성능평가</U></h3>\n<div style=\"text-align: center;\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 512px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/a0de3ac7f5e308894fdbaa7c53e8c620/01e7c/confusion-matrix.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 66%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC5UlEQVR42j1RaU8TURSdv2XiBw3GSCQaPxhjQlwKFqgsRWRxBxGILGoipVVpCdCNKbZISzvT0tJ1ls60pQUVKqllj1iHYECQzszz8sXk5Oack3ty77sPS3c8oysVbE0VU1X5H7SyglLciqvrk53tifYniaePoSY7O9jGBkpxExqo2zcyL55jdI1y9nxJoKwUqu/c2ROUnAEJCJdfj9ytptR1kUpFRFkRU9cHb5bPXboYuFxGnD5FVysxtv4u9AWvXOLrVOm25lRLU6pJvdTTtfLmVXagL9v3cqm/9+vL7i89XSBXBvpymrfZ/t6kum7p9QDG1qrmLl7wl5XuetwolxPTaZTN7tL0qte76Q8IsRhaXBTn59HCwgHHfSfJPEluh0Ly58/St28nk2Fs+NpV4dMUymSKLItSqSLP7UWju+HwMc/J8ymR56REQkwmwSwEg0fxuMzz4uIixrU2MwBVtWD/uOElJYaWuTjKpBdwnDeOo/mUDEmWkeIM8E2SCOh0KJlAXFzMZDD+0QO65T59R1HAreszLjkakWkKsUyBJHYIDxBEU1I0IsWiKM7+8pL5KUeRiiEqBotgiccPmHtqCAtWy8b0J2kugKKRP7O+HI5nLeZ9L4liUSk4h8IhKRxanbQtm807LidIkeMwruU+1djAqKoE47gc8Bc9bnnWd0wSB+6ZQ4L4S3hAioRHJAnR5z1wucA8JDwSSRRjUYx/2Mq0tcDNhRHDTxsuOqelGRfyedNaTaivF5GE7J4RXU4A8G2zyd35/Bi4y1kMBTEe1n7YBuHC+3d5g162f0Rwdqdz3WDI6rTIOQ1SctgBEPiNTyxrh4pTDuSwi34/xrc2U/W1TI1SGNLkNIOi2YQmbftjo/nBt+vaISDIhksWM5qw/jWbtnTaNY1md8SArBZ4C5bq6aabGuG3dvTDgtl0MGE9mrQJJmN++MPWiKFgHAcJ5qEN37Na8vrhNf3wj7HRI6vlD0n8A9/JJlOj4VGTAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"confusion matrix\" title=\"\" src=\"/static/a0de3ac7f5e308894fdbaa7c53e8c620/01e7c/confusion-matrix.png\" srcset=\"/static/a0de3ac7f5e308894fdbaa7c53e8c620/772e8/confusion-matrix.png 200w,\n/static/a0de3ac7f5e308894fdbaa7c53e8c620/e17e5/confusion-matrix.png 400w,\n/static/a0de3ac7f5e308894fdbaa7c53e8c620/01e7c/confusion-matrix.png 512w\" sizes=\"(max-width: 512px) 100vw, 512px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span><br>\n  <b>confusion-matrix</b> <br><br>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 150px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/558ac23c0b9a4130bb0555c347934deb/8a4e8/confusion-matrix-explain.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 95.33333333333334%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAAA7DAAAOwwHHb6hkAAACJ0lEQVR42r2Uz2sTQRTH8wd58CZ48sdZ9CB6ERULKtJDC4IoBXuIFLPUi5rSQOwP+iPFekmbUDBN2rQl/ZEWGm2TYtNCqQlN25Afm2R3dna+TnaypsE0RisOPObNzrzPfN/szLPgHzfLmaIZq9ofA08EnV2hCSv3ui7cggz98Ah6MgH94Ojn/C9ASik3rWIUjAPKCI0Hk2wWpk66+RWq2wMyO8MtdDqwrrLlVWDCC3AAi3xBadgFGtsCK5bAZK6Ub1SbciWQEgWDHxyQJAmS7TXe9PRiZ3oOY7dvwWa34+07O6KP24HollBaSf/UM6QaQSKRgPN9Nx62tmP3MI2004n7V68gGApjyufB3XPnocwtCR38SBr+Zb28gLcZ70d0dHUbvjo8iCctD5DKFI1xy+VLiDuGqsBGCk2gz+3Cc6vN8DXXCO7cvAGHcwBW60t0tj0DPvubS9kEBrzj6HglCeDoCO5dv4a+/iEsr0egbkRBpgOVgCaB/skxvOjsEsBJNx5duIiDEjHGBdc4vzKx5oCUigWR8CJGP02Ij7kcFlqf4nhtHXQhZFyZRi/HcnIun6fwBY7hD2YxO5+DZyqFve8qoBSguL0gwXkwVW3u6SmKjs2YjO1vMiIbeezEZT4uIJksYj+lVkXVSbMGaKpTOXBpJYO11QwWw1mscD8QTGObg+P7SvmOgGn0t0XCUq8aifNmhhHCwP6mHpqFRPSstsj8twJbB/gD7LKfz2t6io8AAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"confusion matrix explain\" title=\"\" src=\"/static/558ac23c0b9a4130bb0555c347934deb/8a4e8/confusion-matrix-explain.png\" srcset=\"/static/558ac23c0b9a4130bb0555c347934deb/8a4e8/confusion-matrix-explain.png 150w\" sizes=\"(max-width: 150px) 100vw, 150px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span> <br>\n</div>\n- TP(True Positive) : 긍정예측을 성공, 환자라고 예측해서 실제 환자임을 맞춤<br>\n- TN(True Negative) : 부정예측을 성공, 비환자라고 예측하여 실제 비환자임을 맞춤<br>\n- FP(False Positive) : 긍정예측을 실패, 환자라고 예측했지만 비환자임<br>\n- FN(False Negative) : 부정예측을 실패, 비환자라고 예측했지만 실제 환자임\n<p><br><br></p>\n<h4>분류성능평가지표</h4>\n<hr>\n<ul>\n<li><strong>Precision (정밀도)</strong></li>\n</ul>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mtext>정밀도</mtext><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">Precision(정밀도) = \\frac{TP}{TP + FP}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal\">rec</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mopen\">(</span><span class=\"mord hangul_fallback\">정밀도</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.1297em;vertical-align:-0.7693em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3603em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">TP</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">FP</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">TP</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></div>\n<p>모델이 True 라고 예측한 것 중 실제 True인 비율<br>\r\n실제 False인 데이터를 True로 잘못 예측하면 큰 영향이 발생하는 경우 recall(재현율)보다 중요 (ex. 스팸메일)</p>\n<p><br><br></p>\n<ul>\n<li><strong>Recall (재현율)</strong></li>\n</ul>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo stretchy=\"false\">(</mo><mtext>재현율</mtext><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">Recall(재현율) = \\frac{TP}{TP + FN}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\">ec</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">ll</span><span class=\"mopen\">(</span><span class=\"mord hangul_fallback\">재현율</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.1297em;vertical-align:-0.7693em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3603em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">TP</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">FN</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">TP</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></div>\n<p>실제 True인 것 중에서 모델이 True라고 예측한 비율<br>\r\n실제 True인 데이터를 False로 잘못 예측하면 큰 영향이 발생하는 경우 precision(정밀도)보다 중요 (ex. 암 진단)</p>\n<br>\n<blockquote>\n<h4>Precision-Recall Trade-off</h4>\n<p>모델의 분류 결정 임계값(threshold) 설정에 따라 Precision(정밀도) 과 Recall(재현율)이 trade-off 관계로 변화하여 함께 늘리기가 힘듬.<br>\r\n정밀도와 재현율 중에 더 중요한 지표가 무엇인지 판단하고 임계값(threshold)을 조정 해야함.<br><br></p>\n</blockquote>\n<p><br><br></p>\n<ul>\n<li><strong>Accuracy (정확도)</strong></li>\n</ul>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>A</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi><mo stretchy=\"false\">(</mo><mtext>정확도</mtext><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">Accuracy(정확도) = \\frac{TP + TN}{TP + TN + FP + FN}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\">cc</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">cy</span><span class=\"mopen\">(</span><span class=\"mord hangul_fallback\">정확도</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.1297em;vertical-align:-0.7693em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3603em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">TP</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TN</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">FP</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">FN</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">TP</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TN</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></div>\n<p>전체 결과에서 True를 True로 False를 False로 예측한 비율 (precision과 recall과 다르게 False를 False라고 예측한 경우도 포함)</p>\n<blockquote>\n<h4>accuracy(정확도) 만 봐서는 안되는 이유</h4>\n<p>actual value가 negative로 편향되어있는 target에 TN이 높은 모델은 전체적으로 accuracy(정확도)는 매우 높지만 TP인 성능은 높지 않을 수 있음.<br>\r\n(ex. 맑은 날이 많은 지역에서, 맑을 것으로 예측하는 성능은 높지만 비가 오는 것을 예측하는 성능은 낮을 수 있음.)<br>\r\n따라서, 이러한 경우 precision(정밀도)과 recall(재현율)을 확인하는 것이 좋음.<br><br></p>\n</blockquote>\n<p><br><br></p>\n<ul>\n<li><strong>f1 score</strong></li>\n</ul>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>F</mi><mn>1</mn></msub><mo>=</mo><mn>2</mn><mo>⋅</mo><mfrac><mrow><mtext>Precision</mtext><mo>⋅</mo><mtext>Recall</mtext></mrow><mrow><mtext>Precision</mtext><mo>+</mo><mtext>Recall</mtext></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.1408em;vertical-align:-0.7693em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">Precision</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord text\"><span class=\"mord\">Recall</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">Precision</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord text\"><span class=\"mord\">Recall</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></div>\n<p>Recall(재현율)와 Precision(정밀도)을 이용하여 <strong>조화평균</strong>을 구하여 평가 척도를 구성하여 <strong>데이터가 불균형한 상태일때 주요 척도</strong>로 사용.</p>\n<p><br><br></p>\n<hr>\n<ul>\n<li><strong>AP (Average Precision)</strong></li>\n</ul>\n<div style=\"text-align: center;\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 647px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/ad655c5f4d6333909f40a95159fa4c30/ca12d/average-precision.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 68%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsSAAALEgHS3X78AAABrElEQVR42o2S63KbMBCF/f4PlWAQ8KfUNpPY4BiEHZRgLuZ+sQWiKzA0TTJtd87snFnNp9VlF7aNX15MxzlY1h7jw+nkgBzHhjgc7KenrWGYtm1hjC3L2u12sHY8HiF7nrd4eyOqul+vA133n5/PphlgHBISeF4Qx2EUnYPAD0MwPHzfv1wukNM0ZYwtGGtlOUOoVxQuVb3n1ao3jP79vb/d+jkAgNw0TVmWYBZRFAqCL8tMlqkst7MQapdLKopQpIZB64rNcF3Xd5jSG0IxQt1HcpSicMEuggCGJgkb+//unCSxKIYIfe78aRdJ4nyWdX90Loococu3nb/ymtbCwZtmgvM8k8RogOnfeVWB81NCGKUTXFWlJP278yhJotqPrihqoDgMZ0BS/J/w8Aud+1pdrxWHsyyVpGj4W7hYp6pcs/noB9Mqcv9TK+HJOHy7XQUhfHhoHh9rQeB5NIIwm3txubwOBippng8wIUTfYEIqjJP1CuY2c91S109703fdwjTOm80RKo6TapoFGfx2S/I85zDj0U3D182TCG9ByKlp4G5sms12Mt04ar8AVizoiFfJ9qEAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"average precision\" title=\"\" src=\"/static/ad655c5f4d6333909f40a95159fa4c30/ca12d/average-precision.png\" srcset=\"/static/ad655c5f4d6333909f40a95159fa4c30/772e8/average-precision.png 200w,\n/static/ad655c5f4d6333909f40a95159fa4c30/e17e5/average-precision.png 400w,\n/static/ad655c5f4d6333909f40a95159fa4c30/ca12d/average-precision.png 647w\" sizes=\"(max-width: 647px) 100vw, 647px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span><br>\n  <b>average-precision</b>\n</div>\n<br>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>A</mi><mi>P</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></munderover><mrow><mo fence=\"true\">[</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo><mo>−</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo fence=\"true\">]</mo></mrow><mo>⋅</mo><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">AP = \\sum_{k=0}^{n-1} \\left[ Recalls(k) - Recalls(k+1) \\right] \\cdot Precisions(k)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.1032em;vertical-align:-1.3021em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8011em;\"><span style=\"top:-1.8479em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">0</span></span></span></span><span style=\"top:-3.05em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3021em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">[</span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\">ec</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">ll</span><span class=\"mord mathnormal\">s</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\">ec</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">ll</span><span class=\"mord mathnormal\">s</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mclose delimcenter\" style=\"top:0em;\">]</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal\">rec</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">s</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose\">)</span></span></span></span></span></div>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0</mn><mo separator=\"true\">,</mo><mspace width=\"1em\"></mspace><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn><mo separator=\"true\">,</mo><mspace width=\"1em\"></mspace><mi>n</mi><mo>=</mo><mtext>number of thresholds</mtext></mrow><annotation encoding=\"application/x-tex\">Recalls(n) = 0, \\quad Precisions(n) = 1, \\quad n = \\text{number of thresholds}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\">ec</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">ll</span><span class=\"mord mathnormal\">s</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">n</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal\">rec</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">s</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">n</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8389em;vertical-align:-0.1944em;\"></span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord text\"><span class=\"mord\">number of thresholds</span></span></span></span></span></span></div>\n<br>\n<p>precision-recall 곡선은 알고리즘의 전반적인 성능을 파악하기에는 좋으나 <strong>서로 다른 알고리즘의 성능을 정량적으로 비교</strong>하기에는 어려움으로 AP를 이용하여 비교한다.<br>\r\nAP는 각 threshold에서의 precision의 가중합을 의미하며, 이때의 가중치는 이전 threshold와 현재의 threshold 에서의 recall 값의 차이이다. <br>\r\n결국에 AP는 Precisions의 Average를 대표하는 값으로 볼 수 있다. <br>\r\n값이 클 수록 높은 성능을 의미한다.<br></p>\n<div style=\"text-align: center;\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/c4573b73346f5581531b2aa4fce17eb4/ae694/ROC-precision-recall-compare.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 49.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAB8ElEQVR42k2SC3OiMBSF+f8/qWOhuxWQhLBSfE2LOFhXFAV5Cj7KaRKr08x8k3uTk5ObC0oURcjKHLsyQVoekFUFqqZCVmc4VAfs6h2SPEG8jVFWRyRJhbJsOUekaSXz/b6Uc103UNqmRZRvwdYeZrGP1/8D2HMbxtRA3+uj5/QQRiG+rldMJgs8PbkgZA5NW3DWGA53sO0ter0VNpsCyuVyQVmUKJIcb6s3GEwHsQhsYoNRBmISbKINxAgCH5QOOASDAYFpDrn5jBPyy2JUVcUNrxc0VYP37Tv+uq9wqAPGGGzGDR0Gy7Ig2iLGfD7nRhaviHEN32eUx8KYQNdnvAU1lGgd4ZAfYAYmDNPgBwZcYEpELAzDMOR92iPghiKnlP5oBhLGhCHF52cKpS5qxFWMZ0+F/qfP+6JyNGiqipeXFxiGyYVLZFmGxWIhDQkhUJ9VqOoNUTWlNv8weyjdpcMqW0H7p2FoD+UzGXPgODd+P9n3fZnbtv3YF4hcVJ0kCRR8AR/FB3RLByVU3n6v4v603z0Uudh76H60IhZtUbprBz/14XouRt4I4/GYf7GJZDQawXVdxHGMruvkkz3Pk+tCN51O5SxyQZqmt9+mbVucTic5C4IgQJ7nck1wPp+lYdM0Mhaa4/GI5XL5OHPXfQPk8spv2DS2CgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"ROC precision recall compare\" title=\"\" src=\"/static/c4573b73346f5581531b2aa4fce17eb4/5a190/ROC-precision-recall-compare.png\" srcset=\"/static/c4573b73346f5581531b2aa4fce17eb4/772e8/ROC-precision-recall-compare.png 200w,\n/static/c4573b73346f5581531b2aa4fce17eb4/e17e5/ROC-precision-recall-compare.png 400w,\n/static/c4573b73346f5581531b2aa4fce17eb4/5a190/ROC-precision-recall-compare.png 800w,\n/static/c4573b73346f5581531b2aa4fce17eb4/ae694/ROC-precision-recall-compare.png 850w\" sizes=\"(max-width: 800px) 100vw, 800px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span><br>\n  <b>ROC curve 와 precision-recall curve</b>\n</div>\n<br>\n<p><code>precision-recall curve 와 AP</code> 지표와 비슷한 지표로 <code>ROC curve 와 AUC</code> 지표가 있다.</p>\n<p><br><br></p>\n<ul>\n<li><strong>mAP (mean Average Precision)</strong></li>\n</ul>\n<p>분류시 하나의 객체(binary class)가 아닌 여러 객체(multi-class)의 경우, 모든 class의 AP를 평균낸 값이다.</p>\n<p><br><br></p>\n<hr>\n<h3><U>위치탐지성능평가</U></h3>\n<ul>\n<li><strong>IoU (Intersection over Union)</strong></li>\n</ul>\n<div style=\"text-align: center;\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/65aa2068eb7b45d06bcff83fb61093da/c1c45/IoU.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 37.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACHklEQVR42mWSXUiTYRiGv4NOgrDQJVjDLRMnc4LNzTGhpS4kLbMf8WcR9ANCSBARdKBoB4pCBxohKQphRAdJ1JFkB5lRYIiMWakt2lL3ObO5zTWm+762q21gFN7w8L7PwXs97839CDPiFnb3Ij98LuY/vGbB/p7V9e/4w2G8/jXGJkfxb/hIKh6P86+SnSf8my8BmTm/TESOI7T2DVN/qZaB69dozzpMZ14Rjzrb6Olvoe3uZaptJtyL31KAWCz2Hywp+0+JgyOr1Iyt80tKAM9cbOaoWUOP9Thd1nN0W8/TXVVJy+1jWE7qKC7T4l5ypR7LsowkSalzKyolqDGm12SMz3w0TwYJJ4GqvHwaGk/QbjbTtS+frgwtHeVFVDUWotHnkF2QxewnB9GojD8QwOVys7S0jNP5FdEjsrm5hT8UZj1RgUgUQXdEh8FUwFlrHjf1Gm5Z8rE16NDqVWTmHkChTsfxcTb1w1AolIKJ4gqeZU9iSJTWqQBN4z56ZoJE5RhCaYWRElMxdResNF2ppqaxnJJSHftVmaRnK9irTGPBOf/XchIiSTJywnoypNwna+wa9LJ7yEuvI4xQe6oSW/1p6uqqqCgzozcaKDToUeaoUR5Sk6bI4PP83I5QtmV54WPPsBfhvsiNdxsIU2/GmZp4yfTbV4wM9fNw6AHPR58yODBIb9892jruIK6s7Fib7ZszsTJXJ4KplB87I/wBqCTddSbdLqoAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"IoU\" title=\"\" src=\"/static/65aa2068eb7b45d06bcff83fb61093da/5a190/IoU.png\" srcset=\"/static/65aa2068eb7b45d06bcff83fb61093da/772e8/IoU.png 200w,\n/static/65aa2068eb7b45d06bcff83fb61093da/e17e5/IoU.png 400w,\n/static/65aa2068eb7b45d06bcff83fb61093da/5a190/IoU.png 800w,\n/static/65aa2068eb7b45d06bcff83fb61093da/c1c45/IoU.png 824w\" sizes=\"(max-width: 800px) 100vw, 800px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span><br>\n  <b>IoU</b><br>\n</div>\n<br>\n<p>모델이 얼마나 객체의 위치를 정확히 찾았는지 측정할 수 있는 지표.</p>\n<p><br><br></p>\n<h2>2) 얼마나 빨리 탐지 하였는지 평가 (탐지 속도)</h2>\n<ul>\n<li><strong>FPS (Frames Per Second)</strong></li>\n</ul>\n<p>초당 detection 하는 횟수. 예를 들어 10fps는 초당 10 frame을 detection 함을 의미.</p>","frontmatter":{"title":"Object Detection 평가지표","slug":"/blog/object-detection-evaluation-metric","date":"2025-01-15","category":"ai, cv"}}},{"node":{"html":"<br>\n<h1>R-CNN</h1>\n<h2>R-CNN 의 개요</h2>\n<div style=\"text-align: center;\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/ea3f7281e7a7fc01de84c10c5550e97d/21b4d/R-CNN_features.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 37%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAABYlAAAWJQFJUiTwAAABpElEQVR42l2RS2tTQRTH89X8BK59fAEVERQpitDiShdqrdWFoSJupKBg3bkRwQfl5trc3KZocnNfuc/cZ2MSIzTJz5kRXPTAzGGGOf//75xpcCrG4zFlVVNVIpcVo9GIuq7JspE4l+R5TpIkxHHMfD4/XU7j5GRBlafURcyvOmfohxzo3zDbn/iufUbXD7AGDobRwXUdgiBgMBhg2zZhGCrDLMuYTCb/BKX7zrOHbN/f4F1zgzj4yZvX6zQf3+T9yzXSyMO2dHyvJ8hSptOpIpNZisrlOI7qTAlWx8c8ev6KW5cvsff0OlFosiWEb189y+7WRfa/fuDenSt8+fgW2/FptTRBawhyXRC7RFGk1mw2Y7Va0SiLkgfrN9i8doHdzTUCt0PzyXle3D3D3s45qsImcQ0xjpTf8z8sl0tFKNv0fV+1L7OcrSKUW5GlwrlFEoXUVUXH0Oh0WnTNfRy7rx7mRY5lWZimqcRkpGlKu91G07T/d0pQDtQ8PFRzKYqCo6Mfolg4D0PhPhStLPE8j16vR7fbVZ8hY7FY0O/3FaUkl4J/AcnE8cK6F4SJAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"R CNN features\" title=\"\" src=\"/static/ea3f7281e7a7fc01de84c10c5550e97d/5a190/R-CNN_features.png\" srcset=\"/static/ea3f7281e7a7fc01de84c10c5550e97d/772e8/R-CNN_features.png 200w,\n/static/ea3f7281e7a7fc01de84c10c5550e97d/e17e5/R-CNN_features.png 400w,\n/static/ea3f7281e7a7fc01de84c10c5550e97d/5a190/R-CNN_features.png 800w,\n/static/ea3f7281e7a7fc01de84c10c5550e97d/c1b63/R-CNN_features.png 1200w,\n/static/ea3f7281e7a7fc01de84c10c5550e97d/21b4d/R-CNN_features.png 1280w\" sizes=\"(max-width: 800px) 100vw, 800px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n</div>\n<ol>\n<li>입력 이미지를 받는다.<br></li>\n<li><code>Selective Search</code> 를 통해 약 2000 여개의 영역을 제안(Region Proposals)한다.<br> + 제안된 영역을 CNN을 사용하여 features를 얻기 위해 CNN의 input크기에 맞춰 일정한 크기로 조정한다.<br></li>\n<li>크기를 조정한 영역을 <code>CNN(AlexNet)</code>에 넣어 features를 얻는다.<br></li>\n<li><code>Support Vector machines(SVM)</code>을 이용하여 구해진 features를 분류한다.<br><br></li>\n</ol>\n<h3>Abstract</h3>\n<p> 본 논문은 두가지 핵심을 사용한다.<br></p>\n<ol>\n<li>객체 탐지를 위한 Region Proposals 에 CNN을 적용한다.<br></li>\n<li>labeled 된 훈련 데이터가 부족할때 <code>supervised pre-training</code> 과 <code>domain-specific fine-tuning</code> 을 통해 성능을 향상시킨다.<br><br></li>\n</ol>\n<h2>Object detection with R-CNN</h2>\n<ul>\n<li>\n<h3>Object Localization</h3>\n<p> 논문에서 object localization을 위해 3가지 방법을 제시한다.<br><br></p>\n<ol>\r\n  <li>\r\n    <b>Regression</b><br>\r\n    &nbsp;Szegedy 의 연구의 결과로 좋지 못함을 알고 채택하지 않음.<br>\r\n    <blockquote> C.Szegedy, A.Toshev, and D.Erhan. Deep neural networks for object detection. In NIPS, 2013.</blockquote>\r\n  </li>\r\n  <li>\r\n    <b>Sliding Window</b><br>\r\n    &nbsp;R-CNN은 합성곱 층이 5개인 구조여서, 매우 큰 윈도우 (195\\*195 pixels)와 Strides (32\\*32 pixels)로는 정확한 localization 이 힘들기 때문에 채택하지 않음.<br>\r\n  </li>\r\n  <li>\r\n    <b>Region Proposals</b><br>\r\n    &nbsp;`Selective Search` 를 채택 함.<br>\r\n    <blockquote> C. Gu, J. J. Lim, P. Arbelaez, and J. Malik. Recognition using regions. In CVPR, 2009.</blockquote>\r\n  </li>\r\n</ol>\r\n<br>\n</li>\n<li>\n<h3>Feature Extraction</h3>\n<p> CNN(AlexNet) 을 활용하여 각 region proposal에서 4096 차원의 feature vector을 추출한다.<br><br>\r\n feature vector을 얻기 위해, region proposal을 5개의 합성곱층과 2개의 완전 연결 계층으로 이루어진 CNN(AlexNet)의 input size인 (227*227 pixels)에 맞춰야 한다.<br>\r\n 이를 위해, 어떠한 비율의 box든 input size로 변형(warping)을 해야하는데, 객체 영역만 tight 하게 자른 box가 아닌 p pixels 만큼 여유를 두고 자른 박스를 warping 합니다.(논문에서는 p = 16 을 사용하였다.)<br></p>\n<blockquote>\n<h4>CNN( AlexNet ) 참고 논문</h4>\n<p>C.Szegedy, A.Toshev, and D.Erhan. Deep neural networks for object detection. In NIPS, 2013.<br><br></p>\n</blockquote>\n</li>\n<li>\n<h3>Test-time detection</h3>\n<p> 테스트 단계에서 CNN 을 통하여 얻은 region의 feature를 SVM을 사용하여 각 클래스 마다 점수를 매긴다.<br>\r\n 한 이미지에서 이렇게 점수를 매긴 region을 각 클래스 별 독립적으로 <code>greedy non-maximum suppression</code>을 수행한다.</p>\n<blockquote>\n<h4>NMS (Non-Maximum Suppression)</h4>\n<div style=\"text-align: center;\">\n <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/951e076e741db6163a32222cf6ca6bd1/c4451/NMS_img.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 76.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABYlAAAWJQFJUiTwAAAEN0lEQVR42h3SW0zTBxTH8X+yPe1pyZbsZcuWucQsYrIs6CbiFA1MRUClhQJFsWCVisUWpAUKYqFYhNrWlku5tN6glgKTSYSpXIxKBjZeEZjKRbRsAkqim2TK9l3nSU5+yckv5+kjtHf9RJpmB7kWNflVSo541Xh6HMzPveD/WVhYeJfXB/uRHUzjQKkarT0T6zkl3YPpjD+w8+/bAd68XeR1oCuUVBbw/lcCn4d9yNdxHxOp+oL4jI1YGrw8feXH3uJg8P5tevpbWBcnEJv+HtL8D9h16CNKrUsps2p56DfT0ltHS3cHQqXTxvfhq4mSbmKFaClSyUqOFZUjz82hzLQH8e4tdPZfYXq6g33qIHYrIyk0f4ooaRl1plRkWcWcbNqMsXw5Da12BGutmZXrgpEd2E58TgIRG9egkIpI25lKuTyCbO02Bm7fZHyyDZVmCUbTeprPf0amKgjT4WB0OgmNgWc1tuWcv3gKob3TRYYqjKMlUmx6GbaivUhCgyjT7CU9bi0nXComJoa4df8aJcUhNJ9eTYtzNc31W5FHLcNaGE9+xkrOnk7ilq8TYfjXy1x06rnqsaAUh9PbaMSiiqfTWUJFVjKtp5y0XRvH0/cAT00VN385zFHtKnq9qTjy02g05mHJT6DHrWHi9gDCo7vX6fOYudpaiVW3B/exHMqzUzBpZbgtWtymLMbu+XjxdIR2TyOX+1x0nf2WruZI6o/GUl0SQ7szkXMOBb7eCwjzL+aYHB/B/2SMuZnHgRxlzv+IV88meTk3zcz8LK8XAyT+fkXP3Sku+P4I3Md4+mSE2akR5v2jzM9O8fyZn4U/XyLUu2sJFQcjUkUizvuR/dVijjeo+c13452/xVsD0HOeYZue7ZJwwhRiJAWbUNuTOF2zC5/XxuLvo/z15h9mns8hVJ+x8mXoJ4SIgwhOXkLC/hD2pktRHjLx80AX5sxEhquLGHOZkcSvIFq+jjXyDWyV/8D+jBRSDpTi8TopdNhovtSE0ORtIiI6ipR9UjbKI9kevZbjulzUuWpseTGkySLoutHH4+lpRLtSKDHq2ZGvJjoqmPpCNao8LSd0EeiS13CyzYXQ2HaSiK0Be7likot2sDlmPfItIciTpJTLwijQxXBnqJ/x8YfESWPR6NOJMyjZJNlAgegbtCnbqNy5iiOaLVy60opw+ZKbssOJWCpS0WcnYjPloBOtosmoICNpM2ecBmb9wwzdu0GdOYuG2uyA250UVygoTfoOrz4BRWI0DkcFE/d7EEYGu+l2GehoLCYpOhSHNeAqUxTgow7Q2YPHbmBmcpiph3fprD3EBXcRkbHhgYdKqjTJnDAoOHJwH6eOH2PyTh/CxIiPa+31dHfU4qjRUV9rodJooKbCgMfpwFtn5smjIWanJ7je3hDoVaOxqympNGEqLQ+sEUeVi6a6KkZ9vfwHt68lNI2BIDsAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"NMS img\" title=\"\" src=\"/static/951e076e741db6163a32222cf6ca6bd1/5a190/NMS_img.png\" srcset=\"/static/951e076e741db6163a32222cf6ca6bd1/772e8/NMS_img.png 200w,\n/static/951e076e741db6163a32222cf6ca6bd1/e17e5/NMS_img.png 400w,\n/static/951e076e741db6163a32222cf6ca6bd1/5a190/NMS_img.png 800w,\n/static/951e076e741db6163a32222cf6ca6bd1/c1b63/NMS_img.png 1200w,\n/static/951e076e741db6163a32222cf6ca6bd1/c4451/NMS_img.png 1450w\" sizes=\"(max-width: 800px) 100vw, 800px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n </div>\n<br>\nobject detector가 예측한 bounding box 중에서 정확한 bounding box를 선택하도록 하는 기법<br><br>\n</blockquote>\n<blockquote>\n<p>N. Bodla, B. Singh, R. Chellappa and L. Davis, Soft-NMS — Improving Object Detection with One Line of Code, in 2017</p>\n</blockquote>\n<h4>Run-time analysis</h4>\n<p> 두가지 특징이 detection을 빠르고 효율적으로 만든다.</p>\n<ol>\n<li>모든 클래스에서 CNN의 parameters를 공유한다.</li>\n<li>CNN을 통해 얻은 feature vectors(4k-dimention) 들은 다른 일반적인 접근법들보다 차원이 낮다.</li>\n</ol>\n</li>\n<li>\n<h3>Training</h3>\n<h4>Supervised pre-training</h4>\n<p> CNN(AlexNet)을 거대한 보조 data-set인 ILSVRC2012(이미지만 있고 bounding box 가 없는)로 이미지 분류를 위한 pre-training을 한다.<br><br></p>\n<h4>Domain-specific fine-tuning</h4>\n<p> CNN이 warp된 proposal window(domain)에 잘 작용하기 위해, warp된 region proposal들 만 사용하여 stochastic gradient descent(SGD) 알고리즘으로 CNN parameters 를 훈련시켰다.<br><br></p>\n<h4>Object category classifiers</h4>\n<p> 객체를 분류할때, 찾으려는 객체가 완전히 들어와 있는 box는 positive 이고 객체가 조금이라도 들어와 있지 않는 box는 negative 이다.  그렇다면 객체가 일부 들어간 box는 positive 일까 negative 일까?<br>\r\n 이에 관하여 IoU 임계값이 {0,0.1,...,0.5}중 0.3 인 것이 결과가 가장 좋아 0.3이상인 것은 positive 아닌것은 negative으로 하였다.<br>\r\n CNN을 통해 features가 추출되고 training labels 가 주어지면 linear SVM을 각 클래스마다 훈련시켜야 한다.<br>\r\n 이때 training data가 너무 많아 메모리가 꽉 차는 현상을 막기 위해 <code>hard negative mining method</code>를 채택하였다.</p>\n<blockquote>\n<h4>hard negative mining</h4>\n<p> positive example 과 negative example 을 균형적으로 학습시키 위한 기법.<br>\r\n negative examples 가 있으면 confidence score 순으로 샘플을 선정 후, random하게 선정한 positive examples 를 갖고 하나의 mini-batch로 만들어 사용하는 방법.<br>\r\n 일반적으로 negative examples의 갯수가 훨씬 많은데, 그중 일부만 사용하여 메모리의 사용량을 줄일 수 있다.<br><br></p>\n</blockquote>\n<br>\n</li>\n</ul>\n<h2>Visualization, ablation, and modes of error</h2>\n<ul>\n<li>\n<h3>Visualizing learned features</h3>\n<p> CNN의 첫번째 계층은 경계와 보색을 찾아준다. 두번째 계층부터는 이해하기가 힘든데, 직관적으로 알아보려고 한다. 그 방법은 하나의 feature를 선택하여 마치 객체 탐지기 처럼 사용하는 것이다.<br>\r\n 방법은 다음과 같다.<br></p>\n<ol>\n<li>많은 region proposals에서 feature들의 활성화를 계산한다.</li>\n<li>활성화가 큰 순서대로 정렬 한다.</li>\n<li><code>non-maximum suppression</code>을 수행한다.</li>\n<li>높은 점수의 region을 확인한다.</li>\n</ol>\n<p><br><br></p>\n<div style=\"text-align: center;\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/71a540217695ba3d0aa68350844f97e7/3d22e/R-CNN_figure4.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 39.49999999999999%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAACGElEQVR42g2RW0/aAABG+7OW+GoyX6ZT56IgDhCQm2ABawXaiiBrS4uVArJx8Y7GzThNnGbLstubj/tDZ/0D3zk5n/Dr/oHLUZ/x+RCrpvD5RKLV2qfXsrnomZhVFTUXZHw24OHLLccDl5ORw+PdDWddgyPX4N4tcaxvMuwPES57+xSzq+yqMmohiV5aRq0o1LUSTWWDcszPm4kXbCaidKoFpPBbD5CkVt1FjEawLRtdjqPFXnHaqSFcXY/Ii2FkKUtxa41MxMeWf57tRAQlHSYxN0l5cZKumae+vszhVgZdzCDGg55Rm+Fxn2wqjBhc4HbcRzCqNXLrG9TLMkUpTiXlQ5yZQk6vIidCHOkSd30duxrnQJboOTYNOYmSXEJt1mnoFXaUTVLBeVy7hHC477A4M004ECCwtIi4ukQokaBSLdGopGnvKVyOx2RyEYqZGGuzs+wl/Tz/bvNyagJNSvL321eeHp+4uhoj/Pj5RKOhY5oGbe8Ms6bhOhZZr13Qv4BjO3wwdPQNybN5T6fXpdlsMHAqRNNR3MFHbj5dc352wZ/nfwitjsk732uMkkjHVNHkAqVkACM0Q3lumnpOxCwX2V7xkVpZJhYJokppdvIJtGiIttWi61oUCyKW0UBo6hblfJJTV2NkV2h5dNNrOfJOam3n6dp1Ds0qbXvX65ryBiMMe03uTw74bqs0NYWR6dA2LfqdA/4Dr22RlEx7XocAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"R CNN figure4\" title=\"\" src=\"/static/71a540217695ba3d0aa68350844f97e7/5a190/R-CNN_figure4.png\" srcset=\"/static/71a540217695ba3d0aa68350844f97e7/772e8/R-CNN_figure4.png 200w,\n/static/71a540217695ba3d0aa68350844f97e7/e17e5/R-CNN_figure4.png 400w,\n/static/71a540217695ba3d0aa68350844f97e7/5a190/R-CNN_figure4.png 800w,\n/static/71a540217695ba3d0aa68350844f97e7/c1b63/R-CNN_figure4.png 1200w,\n/static/71a540217695ba3d0aa68350844f97e7/29007/R-CNN_figure4.png 1600w,\n/static/71a540217695ba3d0aa68350844f97e7/3d22e/R-CNN_figure4.png 2010w\" sizes=\"(max-width: 800px) 100vw, 800px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span><br>\n  <b>Figure 4: 5번째 pooling 후 높은 점수 의 후보 영역</b>\n</div>\n<br>\n나열된 점을 dog로 분류하고, 반사된 표면 등 분류된 결과를 볼 수 있다.<br>\n다음 결과로 보아 network는 약간의 class-tuned features와 함께 모양, 질감, 색상 및 재료 속성이 분포된 표현을 학습하는것으로 보인다.<br>\n<br>\n</li>\n<li>\n<h3>Ablation studies</h3>\n<blockquote>\n<h4>Ablation studies</h4>\n<p>특정 요소가 전체 시스템에 어떤 영향을 주는지 확인하고 싶을때 해당 요소를 제거한 시스템과 비교해보며 확인하는 분석 기법.<br><br></p>\n</blockquote>\n<div style=\"text-align: center;\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/3a9a689dd33cf980f4635509de1f43fe/5b503/R-CNN_table2.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 27%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAtklEQVR42lVQSQrEMAzL/x84hWZtkibdIYU5a5AhpXMQtixFrqtSSnDOobWGeZ5Ra8WyLIJ1Xf8qtVKK8I6uE9u2QU3TJMb7viWQD7qJPOcs/K3t+y54L+KHsVfGGgyfQYj3XsCQEAK4jJxm9jFG6RnMEIJzenkll6rgA3TQSDnBGAOt9WNgmLVWKnlfwMqlDKeXs3EcZa5iiDDVoH0baqnyH87zlNrPY8/zjuN49Ou6BNT72dR/aZRwNKdNzwsAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"R CNN table2\" title=\"\" src=\"/static/3a9a689dd33cf980f4635509de1f43fe/5a190/R-CNN_table2.png\" srcset=\"/static/3a9a689dd33cf980f4635509de1f43fe/772e8/R-CNN_table2.png 200w,\n/static/3a9a689dd33cf980f4635509de1f43fe/e17e5/R-CNN_table2.png 400w,\n/static/3a9a689dd33cf980f4635509de1f43fe/5a190/R-CNN_table2.png 800w,\n/static/3a9a689dd33cf980f4635509de1f43fe/c1b63/R-CNN_table2.png 1200w,\n/static/3a9a689dd33cf980f4635509de1f43fe/29007/R-CNN_table2.png 1600w,\n/static/3a9a689dd33cf980f4635509de1f43fe/5b503/R-CNN_table2.png 1976w\" sizes=\"(max-width: 800px) 100vw, 800px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span><br>\n  <b>Table 2: PASCAL VOC 2007에서의 detection average precision(%)</b>\n</div>\n<br>\n&nbsp;R-CNN의 CNN은 AlexNet으로 5계층의 합성곱층과 2계층의 완전연결계층으로 이루어져 있다.<br>\n&nbsp;CNN의 마지막 풀링층을 pool5, 완전연결계층 2계층을 각각 fc6, fc7이라 명명하자.<br>\n<h4>Performance layer-by-layer, without fine-tuning</h4>\n<p> 먼저 fine-tuning을 하지 않았을 때 결과를 비교해 보기 위해 ILSVRC 2012 데이터로만 사전훈련한 CNN을 사용하여 분석하였다.<br>\r\n 위 table 의 1-3행의 결과를 보면, PASCAL VOC 데이터에 fine-tuning을 하지않은 경우 fc7의 결과보다 fc6의 결과가 더 좋은것을 볼 수 있다. 이는, CNN의 매개변수의 29%인 약 1680만개를 mAP 저하없이 제거 할 수 있음을 의미한다.<br>\r\n 이보다 더 놀라운 점은 pool5까지만 있는 네트워크에서도 pool5가 6%만큼의 features를 계산하지 않음에도 불구하고 꽤나 좋은 결과를 보여줬다는 것이다.\r\n 이 결과로 CNN의 표현력의 상당부분은 합성곱층에서 온다는것을 알 수 있다.</p>\n<h4>Performance layer-by-layer, with fine-tuning</h4>\n<p> fine-tuning 을 했을때 결과를 비교해 보자. fc6 와 fc7의 결과가 pool5까지만 했을때 보다 훨씬 좋은것을 볼 수 있다.<br>\r\n 이를 통해 대부분의 성능적 향상은 domain-specific non-linear clssifers(fc6, fc7)을 학습함으로서 얻을 수 있다는 것을 알 수 있다.<br>\r\n<br></p>\n</li>\n<li>\n<h3>Network architectures</h3>\n<div style=\"text-align: center;\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/e018a2b34f01780171091763fcbc2324/e53e8/R-CNN_table3.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 13.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAdElEQVR42k1OSQpFIQzz/hd0Ic6zOBwhnwg+/iI0TUIboZTCOQetNZRSMMZArfXOvTfmnJf33j8wSzydeYJ5IaWE9x7WWhhjEGNECOHj9B64O+eun1JCzvnOl9daQ1Dg9dfwfSf4nRr9/3Zrrdv8tafPO+Q/ERbdbiWExsoAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"R CNN table3\" title=\"\" src=\"/static/e018a2b34f01780171091763fcbc2324/5a190/R-CNN_table3.png\" srcset=\"/static/e018a2b34f01780171091763fcbc2324/772e8/R-CNN_table3.png 200w,\n/static/e018a2b34f01780171091763fcbc2324/e17e5/R-CNN_table3.png 400w,\n/static/e018a2b34f01780171091763fcbc2324/5a190/R-CNN_table3.png 800w,\n/static/e018a2b34f01780171091763fcbc2324/c1b63/R-CNN_table3.png 1200w,\n/static/e018a2b34f01780171091763fcbc2324/29007/R-CNN_table3.png 1600w,\n/static/e018a2b34f01780171091763fcbc2324/e53e8/R-CNN_table3.png 1982w\" sizes=\"(max-width: 800px) 100vw, 800px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span><br>\n  <b>Table 3: PASCAL VOC 2007에서의 두개의 다른 CNN 구조의 detection average precision(%)</b><br>\n  T-Net = AlexNet / O-Net = VGG16\n</div>\n<br>\n&nbsp;위의 결과로 볼 수 있듯, AlexNet 대신 VGG16을 사용하면 성능이 더 좋아집니다. 하지만 연산속도가 7배 느려진다는 단점이 있다.<br>\n<br>\n</li>\n<li>\n<h3>Detection error analysis</h3>\n<blockquote>\n<p>D. Hoiem, Y. Chodpathumwan, and Q. Dai. Diagnosing error in object detectors. In ECCV. 2012.</p>\n</blockquote>\n<p> 저자의 방법에 error mode 를 구하고, fine-tuning 이 error mode를 어떻게 변화시키는지 그리고 저자의 error types 이 DPM과 비교하여 알아보기 위하여 위 논문에서 제시하는 analysis tool을 사용하였다.<br>\r\n<br></p>\n<div style=\"text-align: center;\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/3431a989622ee2bf2f4663e21e49ed0c/587b0/R-CNN_figure5.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 75.99999999999999%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABYlAAAWJQFJUiTwAAAEKklEQVR42iWUaUzURxjGNz0Skzam6Re/tEk1bdJYqzZ+sGo9CzX1KMU9oBJbpRqVygrRao2VprVpqQe7sFBFOUQUVw5PLqFFRahGvNhlr/9e7MIuy8IuCO6BNPw6sfNp8swz876T5zcjm5qaIhaJ4usPILm68Q1acbscRMbGiESjYu7F7TUxOOyk1+UkGBggIvx2u1l4zfT77bidDjxuJ5PPnyOLxCN0NHRSv6uSpgMFtFdsxPxoJt7BbUhdNm6oK2k8lEfnpWRM3bNw+dbg7HFxJauYlj8O8LBlJTZpFpJzOfH4MLKno0OcOneLtUs1XNxwimaFMG5Lwn1DieG+jfx1BVxXnKZJVUTjd6kYL36Gx+qiPqWYRkUZdalHuJ2zAsvV94jHBpA9GwtTqu/g5Xn5zFmmI09ZTNMX5RgOX6HtnoVp87UsWq6jUCmKJZ2lQ12H1+aiZEMhVcoT3NxUIfRz/L35BNHQCLKRcJALNe3syD7PIlU5MxYXsvlTDZ3Hmrhz18rOPVUsTTvDjI8LSV6lQb9Xj8XsZk92BWlby1El6NDJi7ix6zzRkWfIgqEw7fXXuFtTTuJmPa9/qOWl2XmkZV7B8qCLR5fLUGXWMm22hlfmaFioqMTeY+ROVRHpB+qQva9h+vx8EtacJDw8hkyEjNn8gNZWPb9qG8j6qZqMHyopOtuBzWag/VYtR3SN7D5UjfpgFb/pmnG7bXS015J/sp6snBoyf7zA/qNXGRwKI0OMycl/8Q+MIkkefN5BvK4A8egEsfgE/cERgZOHAV8QrzvAaHhcYBN5odtdffR7AnicfoYHR5iYmEAWjyNYa8BqTML4WI7RKsdgT6TPn4vP8wRTcwqW2xuxWL/C4FiN5Fbj77NhFLrtbho9kooe11qMlk3EYqLDwHCIR9fqeLx9Fc6MOfTunYmt7GV67avFhh4612/HphJrO9/Fkfsazvtz8ZisPEhehzP1I3qz38GZ9wbSnbfFjQQ2owKb5osdHE0ooVWuxbwhA0/CEkLHsmgTKaeuPEGNQKlLdRhrogJf9tc4LC70QrupzKM7WY1j9Xo8W5OIC6ZlowKb8upbrEsv55uUUnLlxdyW7yOY+ztt/1hI3FLBl6oSdq8v5ow8H8P+Ah4bHah3lKHbXkGxSkC/UcOTnTnEQyGBzfAQbdf/ovX8JVZuqWL6PC1LFxZwOqceQ5eRdv1lFOpqXv1Aw1sLNOxI1+Mw27leWiWwqeHNucdZtERHdsoZxkVgsueTUzy818I1vZZvvxeHppayIOlPdv3cgNlwj5bLWjIOXmKFqpRPFKdQZuqxW7tprTvOvl9qWaYqY7GyhM/Ty/AHQv9jE43F6O3rFy+gB6fDhmQ18XQ0zNj4uEg78EJ3OSUkm5nQUOCFPhAcEvyaBCGSKGASv5CfiXic/wBSKYB88oMuoQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"R CNN figure5\" title=\"\" src=\"/static/3431a989622ee2bf2f4663e21e49ed0c/5a190/R-CNN_figure5.png\" srcset=\"/static/3431a989622ee2bf2f4663e21e49ed0c/772e8/R-CNN_figure5.png 200w,\n/static/3431a989622ee2bf2f4663e21e49ed0c/e17e5/R-CNN_figure5.png 400w,\n/static/3431a989622ee2bf2f4663e21e49ed0c/5a190/R-CNN_figure5.png 800w,\n/static/3431a989622ee2bf2f4663e21e49ed0c/587b0/R-CNN_figure5.png 970w\" sizes=\"(max-width: 800px) 100vw, 800px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span><br>\n  <b>Figure 5: object characteristics 에 대한 sensitivity</b><br>\n</div>\n<br>\n<div style=\"text-align: center;\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/e9437f67845bc47732ecb7df2381ca82/c9d77/R-CNN_figure6.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 20.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAuklEQVR42i1P0RKDIAzj///TqRMRaAFFvSzl9tC7tE3S1F3XhZQzjuPAHgIycTtPBOKw7/DbhiNGpJTgvcd3XbHO88A2M13kPv45buFSCQoNhGKxpWESE8XCymbOUlYyzrIg8ZiWgvd90RnqeR703uHmzwdVBIVG1YwtLckXyZ1JmyoK95b2bm2IbwqVs5HODjJtscTkOHNViuztSEMhbhQKexEdM0tSax0vFWIzKuyNF2i0M/UyTQP/ACpSMcvOp2ozAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"R CNN figure6\" title=\"\" src=\"/static/e9437f67845bc47732ecb7df2381ca82/5a190/R-CNN_figure6.png\" srcset=\"/static/e9437f67845bc47732ecb7df2381ca82/772e8/R-CNN_figure6.png 200w,\n/static/e9437f67845bc47732ecb7df2381ca82/e17e5/R-CNN_figure6.png 400w,\n/static/e9437f67845bc47732ecb7df2381ca82/5a190/R-CNN_figure6.png 800w,\n/static/e9437f67845bc47732ecb7df2381ca82/c1b63/R-CNN_figure6.png 1200w,\n/static/e9437f67845bc47732ecb7df2381ca82/29007/R-CNN_figure6.png 1600w,\n/static/e9437f67845bc47732ecb7df2381ca82/c9d77/R-CNN_figure6.png 1964w\" sizes=\"(max-width: 800px) 100vw, 800px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span><br>\n  <b>Figure 6: top-ranked false positive(FP) types 의 분포</b><br>\n</div>\n<br><br>\n</li>\n<li>\n<h3>Bounding-box regression</h3>\n<p> error analysis 에 기초하여, 저자는 localization error를 줄이기 위해 간단한 method를 구현하였다.<br>\r\n <code>deformable part model (DPM)</code>에 적용된 bounding-box regression 에 영감을 받아, selective search 의 region proposals 에 대한 pool5의 feature이 주어지면 새로운 detection window를 예측하기 위해 선형회귀 모델을 훈련한다.<br></p>\n<blockquote>\n<p>bounding-box regression 에 대한 자세한 사항은 Appendix C 참고.</p>\n</blockquote>\n<p> Table1, Table2, Figure5를 보면 이러한 간단한 접근이 많은 mislocalized detection들을 해결 하며 mAP를 3~4 point 향상 시키는 것을 볼 수 있다.<br>\r\n<br></p>\n</li>\n<li>\n<h3>Results on PASCAL VOC 2010-12</h3>\n<div style=\"text-align: center;\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/e018a2b34f01780171091763fcbc2324/e53e8/R-CNN_table3.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 13.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAdElEQVR42k1OSQpFIQzz/hd0Ic6zOBwhnwg+/iI0TUIboZTCOQetNZRSMMZArfXOvTfmnJf33j8wSzydeYJ5IaWE9x7WWhhjEGNECOHj9B64O+eun1JCzvnOl9daQ1Dg9dfwfSf4nRr9/3Zrrdv8tafPO+Q/ERbdbiWExsoAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"R CNN table3\" title=\"\" src=\"/static/e018a2b34f01780171091763fcbc2324/5a190/R-CNN_table3.png\" srcset=\"/static/e018a2b34f01780171091763fcbc2324/772e8/R-CNN_table3.png 200w,\n/static/e018a2b34f01780171091763fcbc2324/e17e5/R-CNN_table3.png 400w,\n/static/e018a2b34f01780171091763fcbc2324/5a190/R-CNN_table3.png 800w,\n/static/e018a2b34f01780171091763fcbc2324/c1b63/R-CNN_table3.png 1200w,\n/static/e018a2b34f01780171091763fcbc2324/29007/R-CNN_table3.png 1600w,\n/static/e018a2b34f01780171091763fcbc2324/e53e8/R-CNN_table3.png 1982w\" sizes=\"(max-width: 800px) 100vw, 800px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span><br>\n  <b>Table 1: VOC 2010 test set 에 대한 Detection average precision(%)</b><br>\n</div>\n<br>\n</li>\n<li>\n<h3>Results on ILSVRC2013 detection</h3>\n<div style=\"text-align: center;\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/e018a2b34f01780171091763fcbc2324/e53e8/R-CNN_table3.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 13.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAdElEQVR42k1OSQpFIQzz/hd0Ic6zOBwhnwg+/iI0TUIboZTCOQetNZRSMMZArfXOvTfmnJf33j8wSzydeYJ5IaWE9x7WWhhjEGNECOHj9B64O+eun1JCzvnOl9daQ1Dg9dfwfSf4nRr9/3Zrrdv8tafPO+Q/ERbdbiWExsoAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"R CNN table3\" title=\"\" src=\"/static/e018a2b34f01780171091763fcbc2324/5a190/R-CNN_table3.png\" srcset=\"/static/e018a2b34f01780171091763fcbc2324/772e8/R-CNN_table3.png 200w,\n/static/e018a2b34f01780171091763fcbc2324/e17e5/R-CNN_table3.png 400w,\n/static/e018a2b34f01780171091763fcbc2324/5a190/R-CNN_table3.png 800w,\n/static/e018a2b34f01780171091763fcbc2324/c1b63/R-CNN_table3.png 1200w,\n/static/e018a2b34f01780171091763fcbc2324/29007/R-CNN_table3.png 1600w,\n/static/e018a2b34f01780171091763fcbc2324/e53e8/R-CNN_table3.png 1982w\" sizes=\"(max-width: 800px) 100vw, 800px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span><br>\n  <b>Figure 3: ILSVRC2013 detection test set 에 대한 mAP</b><br>\n</div>\n<br>\n</li>\n</ul>\n<h2>The ILSVRC2013 detection dataset</h2>\n<p>ILSVRC2013 dataset은 PASCAL VOC dataset보다 균일하지 않다. 따라서 데이터 선택에 중요성을 요구한다.</p>\n<ul>\n<li>\n<h3>Dataset overview</h3>\n<p>ILSVRC2013 은 다음과 같이 분류됩니다.<br></p>\n<ul>\n<li><b>val</b> (20,121 개) &#x26; <b>test</b> (40,152 개)<br>\r\n 검증 데이터와 테스트 데이터는 같은 이미지 분포로 이루어져 있고 모든 클래스(200 개)에 대해 bounding box 와 labeled가 되어져 있다.(annotated 됨)</li>\n<li><b>train</b> (395,918 개)<br>\r\n 훈련 데이터는 완전히 annotated 되어 있지 않다.<br></li>\n</ul>\n<br>\n<p> 훈련 데이터는 완전히 annotated 되어 있지 않기 때문에 <code>hard negative mining</code>을 사용 할 수 없다.<br>\r\n 이를 해결하기 위해 검증 데이터를 동일한 비율의 class로 val1과 val2로 같은 양으로 나눈다. 그리고 val1 과 훈련 데이터의 일부를 사용하여 positive examples로 활용한다.<br>\r\n<br></p>\n</li>\n<li>\n<h3>Region proposals</h3>\n<p> ILSVRC 2013에서도 PASCAL VOC에서와 같이 Selective search 가 val1, val2, test 이미지 각각(훈련 데이터는 빼고)에 fast mode 로 적용하는 방식으로 region proposals를 수행한다.<br>\r\n 한가지 다른점이 있다면, selective search는 scale invariant 하기 때문에 이미지의 크기(해상도)에 따라 region 생성의 수에 영향을 미치는데, ILSVRC 이미지는 크기가 일정하지 않다는 것이다.<br>\r\n 이를 위해 selective search를 수행하기 전 각 이미지 마다 500 pixels로 너비를 고정 하였다.<br>\r\n<br></p>\n</li>\n<li>\n<h3>Training data</h3>\n<p> 훈련 데이터는 다음과 같이 만들었다.<br></p>\n<ul>\n<li><b>훈련 데이터</b> = <b>val1 의 <u>모든 selective search 와 ground-truth box</u></b> + <b>train 의 <u>각 class당 N개의 ground-truth box (만약 N개보다 적을경우 모든 box를 사용)</u></b><br></li>\n</ul>\n<p> 저자는 이를 val1 + trainN 라 명명 한다.<br><br>\r\n 훈련 데이터는 R-CNN에서 다음 3가지 절차를 수행하는데 필요하다.</p>\n<ol>\n<li><b>CNN fine-tuning</b> : PASCAL에서 훈련한 것과 같이 val1과 trainN 으로 5만번의 SDG iteration을 수행하여 fine-tuning</li>\n<li><b>SVM 검출기(detector) training</b> : val1과 trainN의 모든 ground-truth boxs를 사용. val1에 Hard negative mining 을 사용하여 5000개의 이미지를 선별. train는 완전히 annotated 되지 않기 때문에 negative examples을 선별하지 않음.</li>\n<li><b>bounding-box regressor training</b> : val1 만 사용하여 훈련</li>\n</ol>\n<p><br><br></p>\n</li>\n<li>\n<h3>Validation and evaluation</h3>\n<p> 결과를 평가 서버에 제출하기 전, 훈련 데이터 사용의 검증과 위의 데이터를 사용하여 훈련한 CNN fine-tuning과 bounding-box regressor의 영향을 val2를 사용하여 검증하였다.<br>\r\n 추가적인 tuning 없이 ILSVRC 에서 R-CNN의 결과를 확인하기 위한것 이기 때문에 모든 시스템의 hyperparameter은 PASCAL에서 사용한것과 똑같이 고정하였다.<br>\r\n val2에서 가장 좋은 결과를 보인 모델을 선택하여, bounding-box regression이 있는 모델과 없는 모델을 ILSVRC2013 평가 서버에 올렸다.<br>\r\n<br>\r\n제출을 위해 사용된 training-set은 다음과 같다.</p>\n<ul>\n<li><b>SVM</b> : val + train1k</li>\n<li><b>bounding-box regressor</b> : val</li>\n<li><b>CNN</b> : val1 + train1k</li>\n</ul>\n<p><br><br></p>\n<p>CNN은 fine-tuning과 feature 계산을 반복 하지 않기 위해 val1 + train1k를 사용하였다.<br>\r\n<br></p>\n</li>\n<li>\n<h3>Ablation study</h3>\n<div style=\"text-align: center;\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/4f3811b395d8469b47f197c834727fc0/06868/R-CNN_tabel4.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 21%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAq0lEQVR42j2QRw6EMBAE/f/fAeLAFUQ2OYqgXtVI7MFu94Ty2G5ZFiVJoizLxHmaJnnvte+7+r7XPM+2hmHQtm1q21bHcZji67rWeZ5/7/I8VxiGiqLIkgQB0TSOo12yrqsB8dSTL4rCICi+qip1XSfHFgSB4jg2INMQu67LAEwKkDiTfLmmacyjeKDUuvd9DfY9mUaSz/MYkKbvK+77NiCapqkpQ8Aoy9LqfjYxLyhjj6COAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"R CNN tabel4\" title=\"\" src=\"/static/4f3811b395d8469b47f197c834727fc0/5a190/R-CNN_tabel4.png\" srcset=\"/static/4f3811b395d8469b47f197c834727fc0/772e8/R-CNN_tabel4.png 200w,\n/static/4f3811b395d8469b47f197c834727fc0/e17e5/R-CNN_tabel4.png 400w,\n/static/4f3811b395d8469b47f197c834727fc0/5a190/R-CNN_tabel4.png 800w,\n/static/4f3811b395d8469b47f197c834727fc0/c1b63/R-CNN_tabel4.png 1200w,\n/static/4f3811b395d8469b47f197c834727fc0/29007/R-CNN_tabel4.png 1600w,\n/static/4f3811b395d8469b47f197c834727fc0/06868/R-CNN_tabel4.png 1974w\" sizes=\"(max-width: 800px) 100vw, 800px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span><br></div>\n<p><b>Table 4: data usage choices, fine-tuning, bounding-box regression 에 관한 ILSVRC2013 ablation study </b><br></p>\n</div>\r\n<br>\n</li>\n<li>\n<h3>Relationship to OverFeat</h3>\n<p>R-CNN 과 OverFeat은 다음과 같은 차이점을 제외하면 매우 비슷하다. <br></p>\n<table>\n<thead>\n<tr>\n<th>R-CNN</th>\n<th></th>\n<th>OverFeat</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>selective search</td>\n<td>영역추정</td>\n<td>multi-scale pyramid</td>\n</tr>\n<tr>\n<td>per-class BB regressor</td>\n<td>BB</td>\n<td>single BB regressor</td>\n</tr>\n</tbody>\n</table>\n<br>\r\nOverFeat은 R-CNN보다 성능은 떨어지지만 9배 더 빠르다. 이러한 속도적 이점은 sliding windows 기법은 이미지 warping이 필요 하지 않기 때문이다.<br>\r\n<br>\n</li>\n</ul>\n<h2>Conclusion</h2>\n<p>Abstract 에서 말한것과 같이,<br></p>\n<ol>\n<li>region proposals 를 통한 객체탐지</li>\n<li>labeled 된 훈련 데이터가 부족할때 supervised pre-training 과 domain-specific fine-tuning 을 통해 성능을 향상<br></li>\n</ol>\n<p>=> labeled되지 않은 많은 데이터로 supervised pre training을 하고 (image classification) 그리고 나서 적은 labed된 영역을 가지고 fine-tuning한다 (detection).\r\n<br></p>\n<p>을 통하여 좋은 결과를 보였다.</p>","frontmatter":{"title":"[논문 리뷰] R-CNN","slug":"/blog/rcnn-review","date":"2023-05-02","category":"ai, cv"}}},{"node":{"html":"<br>\n<h1>자료구조</h1>\n<h2>Stack (스택)</h2>\n<p>FILO 구조. 자동메모리, 네트워크 프로토콜, 되돌리기 등에 사용.</p>\n<h2>Queue (큐)</h2>\n<p>FIFO 구조. 작업을 처리하는 요소에 많은 데이터가 한번에 몰렸을경우, 큐 자료구조를 사용하여 대기하는 줄을 만들어 작업에 무리가지 않게 '<strong>완충장치</strong>'로 도 사용.</p>\n<h2>Tree (트리)</h2>\n<ul>\n<li>\n<h3>Binary Tree (이진 트리)</h3>\n하나의 노드가 자식노드를 2개까지만 가질 수 있는 트리.<br> 수식을 트리처럼 표현하여 계산하게 하는 <code>Expression Binary Tree(수식 이진 트리)</code> 와\r\n빠른 데이터 검색을 가능하게 하는 <code>Binary Search Tree(이진 탐색 트리)</code> ,<code>Red Black Tree(레드 블랙 트리)</code> 등의 토대가 된 자료구조.<br><br><br></li>\n</ul>\n<h1>알고리즘</h1>\n<h2>정렬</h2>\n<ul>\n<li>\n<h3>버블정렬</h3>\n이웃요소끼리 비교하며 제일 앞 부터 정렬된 곳 까지 반복하여 정렬 순대로 맞춰가는 방식.<br>\r\n성능은 매우 나쁘나 구현이 간단하여 버그를 만들 가능성이 적다.</li>\n<li>\n<h3>삽입정렬</h3>\n앞에서 부터 정렬 범위를 넓혀가며 새로운 요소의 위치를 옮겨 정렬을 맞추는 방식.<br>\r\n최악의 경우 버블정렬의 성능과 같으나 평균적으로는 조금 더 낫다.</li>\n<li>\n<h3>퀵 정렬</h3>\n기준 요소 선정 하여 기준보다 작은 것은 왼쪽 큰것은 오른쪽으로 이동. 이동완료 후 왼쪽과 오른쪽 부분으로 나눈다.<br>\r\n분할된 요소에 대해 반복적으로 <strong>기준요소 선정 > 요소 이동 > 분할</strong> 을 하여 정렬을 맞추는 방식.<br>\r\n매우 빠른 속도로 정렬 할 수 있다.</li>\n</ul>\n<h2>탐색</h2>\n<ul>\n<li>\n<h3>순차탐색</h3>\n<p>처음부터 끝까지 모든 요소를 검사하는 전략. 성능은 나쁘나 구현이 간단하여 버그를 만들 가능성이 적다.</p>\n<ul>\n<li>\n<h4>전진 이동법</h4>\n</li>\n<li>\n<h4>전위법</h4>\n</li>\n<li>\n<h4>계수법</h4>\n</li>\n</ul>\n</li>\n<li>\n<h3>이진탐색</h3>\n<p><code>정렬된 배열</code> 에 사용 할 수 있는 '<strong>고속</strong>' 탐색 알고리즘.<br>\r\n중앙 요소를 선택 후 작은 요소는 왼편 큰 요소는 오른편에 위치 하므로, 중앙값이 원하는 값이 아니라면 원하는 값을 찾을 때까지\r\n왼쪽 또는 오른쪽 부분을 탐색 대상으로 선정하여 탐색하는 방법.<br></p>\n</li>\n<li>\n<h3>이진 트리 탐색</h3>\n<ul>\n<li>\n<h4>Binary Search Tree (이진 탐색 트리)</h4>\n링크드 리스트처럼 동적으로 노드를 추가,제거 할 수 있으면서 이진 탐색 알고리즘을 사용 할 수 있는 자료구조.<br>\r\n빠른 탐색이 가능하다.</li>\n<li>\n<h4>Red Black Tree (레드 블랙 트리)</h4>\n불균형하게 성장된 이진 탐색 트리는 검색 효율이 매우 낮으므로 균일하게 성장하는 이진탐색 트리를 위한 자료구조.<br>\r\n평균적으로 이진탐색트리에 비해 더 빠른 탐색이 가능하다.</li>\n</ul>\n</li>\n</ul>\n<h2>우선순위 큐와 힙</h2>\n<ul>\n<li>\n<h3>Heap (힙)</h3>\n효율적인 <code>우선순위 큐</code>를 구현할때 사용되는 이진트리 기반 자료구조.<br>\r\n트리내 모든 노드는 부모 노드보다 우선순위가 낮아야 한다. 힙에서 가장 우선순위가 높은 노드는 뿌리 노드이다.<br>\r\n이진 탐색은 할 수 없다.</li>\n</ul>\n<h2>해시 테이블</h2>\n<ul>\n<li>\n<h3>Hash Table (해시 테이블)</h3>\n데이터를 담을 테이블을 미리 크게 확보해 놓은 후 입력 받은 데이터를 해싱하여 테이블 내 주소를 계산하고 이 주소에 데이터를 담는 방법.\n<ul>\n<li>\n<h4>충돌 해결기법</h4>\n<ul>\n<li>\n<h5>Open Hashing (개방 해싱)</h5>\n해시 테이블의 주소 바깥에 새로운 공간을 할당하여 문제를 수습하는 방법</li>\n<li>\n<h5>Closed Hashing (폐쇄 해싱)</h5>\n처음에 주어진 해시 테이블 공간 안에서 문제를 해결하는 방법</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<h5>Open Addressing (개방 주소법)</h5>\n<p>충돌이 일어나면 해시 테이블 내의 새로운 주소를 탐사하여 충돌된 데이터를 입력하는 방식으로 동작.<br>\r\n<em><strong>선형 탐사, 제곱 탐사, 이중 해싱, 재해싱</strong></em> 등이 있다.</p>\n<ul>\n<li>\n<h5>이중해싱</h5>\n해시 함수 2개를 준비하여 하나는 최초의 주소를 얻을때, 또 다른 하나는 충돌이 일어날 때 탐사 이동폭을 얻기 위해 사용하는 방법.<br>\r\n탐사 이동폭의 규칙성은 없애면서도 같은 키에 대해서는 항상 똑같은 결과를 얻을 수 있다.</li>\n<li>\n<h5>재해싱</h5>\n해시 테이블의 여유공간 거의 찼을경우 성능저하를 막아낼 방법이 없기에 해시 테이블 크기를 늘리고 늘어난 해시 테이블 크기에 맞춰 테이블 내의 모든 데이터를 다시 해싱하는 방법.<br>\r\n통계적으로 해시 테이블 공간 사용률이 70%~80%에 이르면 성능 저하가 나타나므로 임계치를 75% 수준으로 설정하는것이 일반적이다.</li>\n</ul>\n<h5>Chaining (체이닝)</h5>\n<p>체이닝 기반 해시 테이블은 데이터 대신 링크드 리스트 또는 이진트리에 대한 포인터를 관리 하도록 하여, 충돌이 일어날 경우 해당 주소의 링크드 리스트 또는 이진트리에 데이터를 저장하는 방식.</p>\n</blockquote>\n</li>\n</ul>","frontmatter":{"title":"자료구조 및 알고리즘","slug":"/blog/data-structure-and-algorithm","date":"2023-01-15","category":"cs"}}}]}},"pageContext":{}},"staticQueryHashes":["3649515864","63159454"],"slicesMap":{}}