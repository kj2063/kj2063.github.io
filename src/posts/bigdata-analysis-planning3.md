---
title: "빅데이터 분석 기획 (데이터 수집 및 전환)"
slug: "/blog/bigdata-analysis-planning3"
date: "2025-03-18"
category: bigdata
---
# 데이터 수집 및 저장 계획

## 데이터 수집 및 전환

### 1. 데이터 수집

#### 1) 비즈니스 도메인과 원천 데이터 정보 수집

- **비즈니스 도메인 정보**
    - 비즈니스 모델
    - 비즈니스 용어집
    - 비즈니스 프로세스
    - 도메인 전문가 인터뷰

<br>

- **원천 데이터 정보**
    - 데이터의 수집 가능성(수집 용이성 등...)
    - 데이터 보안
    - 데이터 정확성
    - 수집 난이도
    - 수집 비용

<br>

#### 2) 내. 외부 데이터 수집

- **내부 데이터** ← 인터페이스를 통해 실시간으로 수집
    - 서비스 시스템
    - 네트워크 및 서버 장비
    - 마케팅 데이터

<br>

- **외부 데이터** ← 인터넷을 통해 일정 주기로 데이터 수집
    - 소셜 데이터
    - 특정 기관 데이터
    - M2M 데이터
    - LOD(Linked Open Data) : 웹에서 누구나 사용할 수 있도록 무료로 공개되는 연계 데이터

<br>

#### 3) 데이터 수집 기술

- **정형 데이터**
    - ETL(Extract Transform Load)
    - FTP(File Transfer Protocol) : TCP/IP 나 UDP 프로토콜을 통해 원격지 시스템으로부터 파일을 송수신하는 기술
    - API(Application Programming Interface)
    - DBToDB
    - 스쿱(Sqoop) : 관계형 DB(RDBMS)와 하둡(hadoop) 간 데이터를 전송하는 방법

> <b>FTP</b><br>
> - TCP/IP 위에서 동작
> - 서버와 클라이언트를 먼저 연결하고 이후에 데이터 파일을 전송
> - FTP 서비스를 제공하는 서버와 접속하는 클라이언트 사이에 두개의 연결(**데이터 제어 연결**, **데이터 전송 연결**)을 생성.
> - **데이터 제어 연결** : 데이터 전송에 필요한 정보를 처리 
> - **데이터 전송 연결** : 실제 데이터 송수신 작업 처리
> - **특징** : 동작 방식이 단순하고 직관적, 빠른 속도로 많은 파일을 한꺼번에 주고 받을 수 있다.

> **스쿱(Sqoop)**
> 관계형 데이터 스토어 간 대량 데이터를 효과적으로 전송하기 위해 구현된 도구
> - 커넥터를 사용하여 관계형 DB(RDBMS) 데이터를 맵리듀스(Mapreduce)를 통해 하둡 파일시스템(HDFS, Hive, Hbase) 으로 수집
> - 하둡 파일시스템으로 수집된 데이터들을 하둡 맵리듀스(Mapreduce)로 변환하고 다시 관계형 데이터베이스로 내보낼 수 있다.
> - 맵리듀스를 통해 처리하기 때문에 병렬처리 가능
> - **특징** 
>   - Bulk import 지원 : 전체 데이터베이스를 HDFS로 전송가능
>   - 데이터 전송 병렬화
>   - Direct input 제공 : RDB에 매핑하여 Hbase와 Hive에 직접 import 제공
>   - 프로그래밍 방식의 데이터 인터랙션 : 자바 클래스 생성을 통한 데이터 상호작용 지원
> <div style="text-align: center;">
>  <img src="../images/posts/apache-sqoop.png"><br>
> </div>


<br>

- **비정형 데이터**
    - 크롤링(Crawling)
    - RSS(Rich Stie Summary) : 웹사이트에 게시된 새로운 글을 공유하기 위해 XML 기반으로 정보를 배포하는 프로토콜
    - Open API
    - 척와(Chukwa) : 분산 시스템으로 데이터를 수집. 하둡 파일시스템에 저장. 실시간으로 분석할 수 있는 기능 제공.
    - 카프카(Kafka) : 대용량 실시간 로그처리를 위한 분산 스트리밍 플랫폼 기술

<br>

- **반정형 데이터** ← 비정형 데이터 수집 기술도 적용 가능
    - 플럼(Flume) : 분산 환경에서 대량의 로그 데이터를 수집 전송하고 분석하는 기능 제공
    - 스크라이브(Scribe) : 다수의 수집 대상 서버로부터 실시간으로 데이터를 수집. 분산 시스템에 데이터를 저장하는 기능을 제공.
    - 센싱(Sencing) : 센서로부터 수집 및 생성된 데이터를 네트워크를 통해 활요하여 수집하는 기능 제공
    - 스트리밍(Streaming) - TCP,UDP,Bluetooth,RFID : 네트워크를 통해 미디어 데이터를 실시간으로 수집하는 기술


> **플럼(Flume)**
>  대용량의 로그 데이터를 효과적으로 수집, 집계, 이동 시키는 신뢰성 있는 분산 서비스를 제공하는 솔루션
> - 스트리밍(Streaming) 데이터 흐름에 기반을 둔 간단하고 유연한 구조
> - 플럼의 하나의 에이전트는 소스, 채널, 싱크로 구성
>   - **소스** : 웹서버, 로그데이터 서버 등 원시데이터 소스와 연결
>   - **채널** : 큐 구조를 갖음. 소스로 부터 데이터 수신. 싱크로 데이터 송신.
>   - **싱크** : 목표 시스템으로 수신받은 데이터 전달
> - **특징** : 대량의 이벤트 데이터 전송을 위해 사용
>   - 신뢰성 : 장애 시 로그 데이터의 유실 없이 전송을 보장
>   - 확장성 : 수평확장 가능하여 분산수집 가능한 구조
>   - 효율성 : 커스터마이징 가능하며 고성능 제공
> <div style="text-align: center;">
>  <img src="../images/posts/apache-flume.png"><br>
> </div>

> **스크래피(Scrapy)**
> 웹사이트를 크롤링하고 구조화된 데이터를 수집하는 도구
> - API를 이용하여 다양한 형식의 데이터를 추출가능. 범용 웹 크롤러로 사용.
> - **특징**
>   - 파이썬 기반
>   - 단순한 스크랩 과정 : 크롤링 후, 바로 데이터 처리 가능
>   - 다양한 부가 요소 : scrapyd, scrapinghub 등 부가요소, 쉬운 수집, 로깅을 지원

<br><br>

### 3. 데이터 변환